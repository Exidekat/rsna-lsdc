{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71549,
     "databundleVersionId": 8561470,
     "sourceType": "competition"
    },
    {
     "sourceId": 8727685,
     "sourceType": "datasetVersion",
     "datasetId": 5236783
    },
    {
     "sourceId": 8728463,
     "sourceType": "datasetVersion",
     "datasetId": 5238658
    },
    {
     "sourceId": 8761420,
     "sourceType": "datasetVersion",
     "datasetId": 5264030
    },
    {
     "sourceId": 9231709,
     "sourceType": "datasetVersion",
     "datasetId": 5583775
    },
    {
     "sourceId": 9235934,
     "sourceType": "datasetVersion",
     "datasetId": 5586514
    },
    {
     "sourceId": 9238129,
     "sourceType": "datasetVersion",
     "datasetId": 5587999
    },
    {
     "sourceId": 9238150,
     "sourceType": "datasetVersion",
     "datasetId": 5588015
    },
    {
     "sourceId": 9273089,
     "sourceType": "datasetVersion",
     "datasetId": 5611997
    },
    {
     "sourceId": 9306154,
     "sourceType": "datasetVersion",
     "datasetId": 5635376
    },
    {
     "sourceId": 9365806,
     "sourceType": "datasetVersion",
     "datasetId": 5679443
    },
    {
     "sourceId": 9409759,
     "sourceType": "datasetVersion",
     "datasetId": 5577143
    },
    {
     "sourceId": 184402550,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 192715298,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193161758,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193298353,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193335312,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193338638,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 193417638,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 100132,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 64905,
     "modelId": 89293
    },
    {
     "sourceId": 111113,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 85952,
     "modelId": 84065
    }
   ],
   "dockerImageVersionId": 30762,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "One of the [outstanding members](https://www.kaggle.com/cdeotte) of the Kaggle community, grandmaster, gives a link to his [work](https://www.kaggle.com/code/cdeotte/top-solutions-ensemble-0-947), where he shows the refinement of the prediction using an experimental example. In order to try to refine our predictions at the [RSNA 2024 Lumbar Spine Degenerative Classification](https://www.kaggle.com/competitions/rsna-2024-lumbar-spine-degenerative-classification/leaderboard) competition\n",
    "\n",
    "**[RSNA | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/rsna-ensemble-solutions)** Leaderboard=0.5?\n",
    "\n",
    "1. **0.56**  Japan [[Inference] RSNA2024](https://www.kaggle.com/code/takashimanaoya/inference-rsna2024) by expert [Naoya](https://www.kaggle.com/takashimanaoya)\n",
    "2. **0.56** Gliser [[Inference] RSNA2024-Normalize-Change](https://www.kaggle.com/code/drqingyang/inference-rsna2024-normalize-change) by contributor [Yang](https://www.kaggle.com/drqingyang)\n",
    "3. **0.57** Türkiye [84% Accuracy in Spine Classification Using CNN](https://www.kaggle.com/code/regisvargas/fork-of-neurips-ariel-2024-starter-5be123) by contributor [AIMED](https://www.kaggle.com/ceng49)\n",
    "4. **0.59** USA [RSNA2024 LSDC DenseNet Submission](https://www.kaggle.com/code/hugowjd/rsna2024-lsdc-densenet-submission) by expert [Jiadi Wang](https://www.kaggle.com/hugowjd)\n",
    "5. **0.56** Egypt [RSNA Lumbar Spine Prediction](https://www.kaggle.com/code/marwanashref/rsna-lumbar-spine-prediction) by expert [Marwan Ashref](https://www.kaggle.com/marwanashref)\n",
    "6. **0.57** Japan [RSNA[INF]edgenext_base_x512[LB.57]](https://www.kaggle.com/code/hideyukizushi/rsna-inf-edgenext-base-x512-lb-57) by expert [yukiZ](https://www.kaggle.com/hideyukizushi)\n",
    "7. **0.54** Germany [LSDC Yolo Approach](https://www.kaggle.com/code/namgalielei/lsdc-yolo-approach) by master [Liam Nguyen](https://www.kaggle.com/namgalielei)\n",
    "8. **0.55** Japan [LB0.55 | Inference by tempature0.9 | RSNA2024](https://www.kaggle.com/code/taikimori/lb0-55-inference-by-tempature0-9-rsna2024) by expert [Taimo](https://www.kaggle.com/taikimori)\n",
    "9. **0.51** USA [3D Vision Transformer Single-Stage (Inference)](https://www.kaggle.com/code/vsahin/3d-vision-transformer-single-stage-inference) by contributor [Victor S](https://www.kaggle.com/vsahin)\n",
    "\n",
    "\n",
    "#### options\n",
    "\n",
    "- option 1 -> LB=0.57 work (1,2)\n",
    "- option 2 -> LB=0.57 work (2,3) \n",
    "- option 3 -> LB= ?.?? work (3,4)         \n",
    "- option 4 -> LB=1.30 work (1,2,4)\n",
    "- option 5 -> LB=0.57 work (2,3) + weights(0.45+0.55)\n",
    "- option 6 -> LB=0.57 work (2,3) + weights(0.55+0.45)\n",
    "- option 7 -> LB=? work (5,6)\n",
    "- option 8 -> LB=? work (5,6) + weights(0.90+0.10)\n",
    "- option 10-> LB=0.54 work (6,7) + weights(0.005+0.995)\n",
    "- option 11-> LB=? work (5,6,7) + weights(0.0005+0.0025+0.997)\n",
    "- option 13-> LB=**0.52** work (7,8) + weights(0.95+0.05)  - It came from an ensemble of two works (7 & \n",
    "8) <=> (0.54 & 0.55)\n",
    "- option 14-> LB=0.51 work (7,8) + weights(0.85+0.15) - It came from an ensemble of two works (7 & \n",
    "8) <=> (0.54 & 0.55)\n",
    "- option 12-> LB=0.48 work (7,9) + weights(0.20+0.80) - It came from an ensemble of two works (7 & \n",
    "9) <=> (0.54 & 0.51) \n",
    "- option 17-> LB=0.48 work (7,9) + weights (0.257+0.743) \n",
    "- option 18-> LB=0.48 work ( 7,9 ) + weights ( 0.33+0.67 )\n",
    "- option 19-> LB=0.48 work ( 7,9 ) + weights ( 0.450+0.550 ) - previus.1 best option\n",
    "- option 20-> LB=0.48 work ( 7,9 ) + weights ( 0.50+0.50 )\n",
    "- option 23-> LB=0.48 work ( 7,9 ) + weights ( 0.473+0.527 )\n",
    "- option 24-> LB=0.48 work ( 7,9 ) + weights ( 0.427+0.573 ) - previus.2 best option\n",
    "- option 25-> LB=0.48 work ( 7,9 ) + weights ( 0.402+0.598 ) - previus.3 best option\n",
    "- option 26-> LB=0.49 work ( 7,9 ) + weights ( 0.377+0.623 )\n",
    "- **option 27**-> LB=**0.48** work ( 7,9 ) + weights ( 0.407+0.593 ) - **best option**\n",
    "- option 28-> LB=0.48 work ( 7,9 ) + weights ( 0.395+0.605 )\n",
    "- option 29-> LB=0.48 work ( 7,9 ) + weights ( 0.402+0.598 )\n",
    "- option 30-> LB=0.48 work ( 7,9 ) + weights ( 0.405+0.595 )\n",
    "- option 31-> LB=0.48 work ( 7,9 ) + weights ( 0.415+0.585 )\n",
    "- option 32-> LB=0.48 work ( 7,9 ) + weights ( 0.410+0.590 )\n",
    "\n",
    "some rezult:\n",
    "* option.18 < option.20 < option.19 < option.24 == (version.48 < version.51 < version.49 < version.55-56)\n",
    "* option.24 < option.25 == (version.55-56 < version.58)\n",
    "* option.25 < option.28 < **option.27** == (version.58 < version.63 < **version.62**)\n",
    "* option.29 < option.30 < **option.27** == (version.58 < version.63 < **version.62**)\n",
    "* option.31 < option.32 < **option.27** == (version.58 < version.63 < **version.62**)\n",
    "\n",
    "best option:\n",
    "- option.32 < **option.27**\n",
    "\n",
    "current option: \n",
    "- option 33-> LB=0.51 work ( 8,9 ) + weights ( 0.407+0.593 )\n",
    "- option 34-> LB=0.51 work ( 8,9 ) + weights ( 0.410+0.590 )\n",
    "\n",
    "next option:\n",
    "- option 16-> LB=0.4? work ( 7,8,9 ) + weights ( 0.25+0.20+0.55 )"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "LAUNCH_VARIANT = 'option 27'"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:48.675522Z",
     "start_time": "2024-10-01T20:42:46.702211Z"
    }
   },
   "execution_count": 594,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [[Inference] RSNA2024](https://www.kaggle.com/code/takashimanaoya/inference-rsna2024)\n",
    "\n",
    "### [Naoya](https://www.kaggle.com/takashimanaoya)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### My Training Code\n",
    "https://www.kaggle.com/code/takashimanaoya/train-lightning-hydra-baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[References]\n",
    "https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libralies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# import math, random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "# import timm\n",
    "# from timm.utils import ModelEmaV2\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# import albumentations as A\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# import re\n",
    "# import pydicom\n",
    "# from typing import Optional\n",
    "# import glob"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:48.742681Z",
     "start_time": "2024-10-01T20:42:48.672462Z"
    }
   },
   "execution_count": 595,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:48.869495Z",
     "start_time": "2024-10-01T20:42:48.703912Z"
    }
   },
   "execution_count": 596,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# EXP_NO = \"006\"\n",
    "# MODEL_DIR = f\"/kaggle/input/rsna24-a-{EXP_NO}\"\n",
    "# MODEL_NAME = \"tf_efficientnet_b5.ns_jft_in1k\"\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 42\n",
    "# NUM_FOLDS = 5\n",
    "\n",
    "\n",
    "# IMG_SIZE = [512, 512]\n",
    "# IN_CHANS = 30\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "# BATCH_SIZE = 1"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:48.902623Z",
     "start_time": "2024-10-01T20:42:48.852094Z"
    }
   },
   "execution_count": 597,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.001979Z",
     "start_time": "2024-10-01T20:42:48.898724Z"
    }
   },
   "execution_count": 598,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.055440Z",
     "start_time": "2024-10-01T20:42:48.990644Z"
    }
   },
   "execution_count": 599,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "# df.head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.130831Z",
     "start_time": "2024-10-01T20:42:49.038666Z"
    }
   },
   "execution_count": 600,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# study_ids = list(df['study_id'].unique())"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.174768Z",
     "start_time": "2024-10-01T20:42:49.119338Z"
    }
   },
   "execution_count": 601,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.245719Z",
     "start_time": "2024-10-01T20:42:49.163395Z"
    }
   },
   "execution_count": 602,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# LABELS = list(sample_sub.columns[1:])\n",
    "# LABELS"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.287197Z",
     "start_time": "2024-10-01T20:42:49.234635Z"
    }
   },
   "execution_count": 603,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# CONDITIONS = [\n",
    "#     'spinal_canal_stenosis', \n",
    "#     'left_neural_foraminal_narrowing', \n",
    "#     'right_neural_foraminal_narrowing',\n",
    "#     'left_subarticular_stenosis',\n",
    "#     'right_subarticular_stenosis'\n",
    "# ]\n",
    "\n",
    "# LEVELS = [\n",
    "#     'l1_l2',\n",
    "#     'l2_l3',\n",
    "#     'l3_l4',\n",
    "#     'l4_l5',\n",
    "#     'l5_s1',\n",
    "# ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.349626Z",
     "start_time": "2024-10-01T20:42:49.276045Z"
    }
   },
   "execution_count": 604,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.406230Z",
     "start_time": "2024-10-01T20:42:49.346013Z"
    }
   },
   "execution_count": 605,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24TestDataset(Dataset):\n",
    "#     def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "#         self.df = df\n",
    "#         self.study_ids = study_ids\n",
    "#         self.transform = transform\n",
    "#         self.phase = phase\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.study_ids)\n",
    "    \n",
    "#     def get_img_paths(self, study_id, series_desc):\n",
    "#         pdf = self.df[self.df['study_id']==study_id]\n",
    "#         pdf_ = pdf[pdf['series_description']==series_desc]\n",
    "#         allimgs = []\n",
    "#         for i, row in pdf_.iterrows():\n",
    "#             pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n",
    "#             pimgs = sorted(pimgs, key=natural_keys)\n",
    "#             allimgs.extend(pimgs)\n",
    "            \n",
    "#         return allimgs\n",
    "    \n",
    "#     def read_dcm_ret_arr(self, src_path):\n",
    "#         dicom_data = pydicom.dcmread(src_path)\n",
    "#         image = dicom_data.pixel_array\n",
    "#         image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "#         img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n",
    "#         assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n",
    "#         return img\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n",
    "#         st_id = self.study_ids[idx]        \n",
    "        \n",
    "#         # Sagittal T1\n",
    "#         allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n",
    "#         if len(allimgs_st1)==0:\n",
    "#             print(st_id, ': Sagittal T1, has no images')\n",
    "        \n",
    "#         else:\n",
    "#             step = len(allimgs_st1) / 10.0\n",
    "#             st = len(allimgs_st1)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st1)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n",
    "#                     x[..., j] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T1')\n",
    "#                     pass\n",
    "            \n",
    "#         # Sagittal T2/STIR\n",
    "#         allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n",
    "#         if len(allimgs_st2)==0:\n",
    "#             print(st_id, ': Sagittal T2/STIR, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_st2) / 10.0\n",
    "#             st = len(allimgs_st2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st2)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n",
    "#                     x[..., j+10] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T2/STIR')\n",
    "#                     pass\n",
    "            \n",
    "#         # Axial T2\n",
    "#         allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n",
    "#         if len(allimgs_at2)==0:\n",
    "#             print(st_id, ': Axial T2, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_at2) / 10.0\n",
    "#             st = len(allimgs_at2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_at2)+0.0001\n",
    "\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n",
    "#                     x[..., j+20] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Axial T2')\n",
    "#                     pass  \n",
    "            \n",
    "            \n",
    "#         if self.transform is not None:\n",
    "#             x = self.transform(image=x)['image']\n",
    "\n",
    "#         x = x.transpose(2, 0, 1)\n",
    "                \n",
    "#         return x, str(st_id)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.499018Z",
     "start_time": "2024-10-01T20:42:49.394644Z"
    }
   },
   "execution_count": 606,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# transforms_test = A.Compose([\n",
    "#     A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "# ])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.560368Z",
     "start_time": "2024-10-01T20:42:49.484129Z"
    }
   },
   "execution_count": 607,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_ds = RSNA24TestDataset(df, study_ids, transform=transforms_test)\n",
    "# test_dl = DataLoader(\n",
    "#     test_ds, \n",
    "#     batch_size=1, \n",
    "#     shuffle=False,\n",
    "#     num_workers=N_WORKERS,\n",
    "#     pin_memory=True,\n",
    "#     drop_last=False\n",
    "# )"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.623634Z",
     "start_time": "2024-10-01T20:42:49.548736Z"
    }
   },
   "execution_count": 608,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24Model(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model_name: str,\n",
    "#         pretrained: bool,\n",
    "#         features_only: bool,\n",
    "#         in_chans: int,\n",
    "#         n_classes: int,\n",
    "#         n_labels: int,\n",
    "#         loss_name: str,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(\n",
    "#             model_name=model_name,\n",
    "#             pretrained=pretrained, \n",
    "#             features_only=features_only,\n",
    "#             in_chans=in_chans,\n",
    "#             num_classes=n_classes,\n",
    "#             global_pool='avg'\n",
    "#         )\n",
    "#         self.loss_fn = loss_name\n",
    "#         self.n_labels = n_labels\n",
    "    \n",
    "#     def forward(\n",
    "#         self,\n",
    "#         x: torch.Tensor,\n",
    "#         y: Optional[torch.Tensor],\n",
    "#     ) -> dict[str, torch.Tensor]:\n",
    "        \n",
    "#         logits = self.model(x)\n",
    "        \n",
    "#         output = {\"logits\": logits}\n",
    "#         if y is not None:\n",
    "#             loss = 0\n",
    "#             for col in range(self.n_labels):\n",
    "#                 pred = logits[:,col*3:col*3+3]\n",
    "#                 gt = y[:,col]\n",
    "#                 loss = loss + self.loss_fn(pred, gt) / self.n_labels\n",
    "#             output[\"loss\"] = loss\n",
    "        \n",
    "#         return output"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.653454Z",
     "start_time": "2024-10-01T20:42:49.607736Z"
    }
   },
   "execution_count": 609,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# models = []"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.748722Z",
     "start_time": "2024-10-01T20:42:49.649936Z"
    }
   },
   "execution_count": 610,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for i in range(NUM_FOLDS):\n",
    "#     cp = f\"{MODEL_DIR}/{EXP_NO}-{i}/best_model.pth\"\n",
    "# #     cp = f\"{MODEL_DIR}/best_model.pth\"\n",
    "#     print(f'loading {cp}...')\n",
    "#     model = RSNA24Model(MODEL_NAME, False, False, IN_CHANS, N_CLASSES, 25, 'dummy')\n",
    "#     state_dict = torch.load(cp)\n",
    "\n",
    "#     # 予期しないキーを削除\n",
    "#     if 'loss_fn.weight' in state_dict:\n",
    "#         del state_dict['loss_fn.weight']\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     models.append(model)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.783033Z",
     "start_time": "2024-10-01T20:42:49.737376Z"
    }
   },
   "execution_count": 611,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "# y_preds = []\n",
    "# row_names = []\n",
    "\n",
    "# with tqdm(test_dl, leave=True) as pbar:\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (x, si) in enumerate(pbar):\n",
    "#             x = x.to(device)\n",
    "#             pred_per_study = np.zeros((25, 3))\n",
    "            \n",
    "#             for cond in CONDITIONS:\n",
    "#                 for level in LEVELS:\n",
    "#                     row_names.append(si[0] + '_' + cond + '_' + level)\n",
    "            \n",
    "#             with autocast:\n",
    "#                 for m in models:\n",
    "#                     y = m(x, None)[\"logits\"][0]\n",
    "#                     for col in range(N_LABELS):\n",
    "#                         pred = y[col*3:col*3+3]\n",
    "#                         y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "#                         pred_per_study[col] += y_pred / len(models)\n",
    "#                 y_preds.append(pred_per_study)\n",
    "\n",
    "# y_preds = np.concatenate(y_preds, axis=0)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.865202Z",
     "start_time": "2024-10-01T20:42:49.779350Z"
    }
   },
   "execution_count": 612,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make Submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# sub = pd.DataFrame()\n",
    "# sub['row_id'] = row_names\n",
    "# sub[LABELS] = y_preds\n",
    "# sub.head(25)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.895453Z",
     "start_time": "2024-10-01T20:42:49.853805Z"
    }
   },
   "execution_count": 613,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sub.to_csv('submission_1.csv', index=False)\n",
    "# pd.read_csv('submission_1.csv').head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:49.993549Z",
     "start_time": "2024-10-01T20:42:49.891883Z"
    }
   },
   "execution_count": 614,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "We created the dataset, performed training, and inference in this notebook. \n",
    "\n",
    "This competition is a bit complicated to handle the dataset, so there may be a better way.\n",
    "\n",
    "I think there are many other areas to improve in my notebook. I hope you can learn from my notebook and get a better score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [[Inference] RSNA2024-Normalize-Change](https://www.kaggle.com/code/drqingyang/inference-rsna2024-normalize-change) \n",
    "### [Yang](https://www.kaggle.com/drqingyang)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### My Training Code\n",
    "https://www.kaggle.com/code/takashimanaoya/train-lightning-hydra-baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[References]\n",
    "https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libralies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# import math, random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "# import timm\n",
    "# from timm.utils import ModelEmaV2\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# import albumentations as A\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# import re\n",
    "# import pydicom\n",
    "# from typing import Optional\n",
    "# import glob"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.036923Z",
     "start_time": "2024-10-01T20:42:49.982357Z"
    }
   },
   "execution_count": 615,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.125691Z",
     "start_time": "2024-10-01T20:42:50.022325Z"
    }
   },
   "execution_count": 616,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# EXP_NO = \"006\"\n",
    "# MODEL_DIR = f\"/kaggle/input/rsna24-a-{EXP_NO}\"\n",
    "# MODEL_NAME = \"tf_efficientnet_b5.ns_jft_in1k\"\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 42\n",
    "# NUM_FOLDS = 5\n",
    "\n",
    "\n",
    "# IMG_SIZE = [512, 512]\n",
    "# IN_CHANS = 30\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "# BATCH_SIZE = 1"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.160532Z",
     "start_time": "2024-10-01T20:42:50.105084Z"
    }
   },
   "execution_count": 617,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.235027Z",
     "start_time": "2024-10-01T20:42:50.156842Z"
    }
   },
   "execution_count": 618,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.272519Z",
     "start_time": "2024-10-01T20:42:50.231454Z"
    }
   },
   "execution_count": 619,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "# df.head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.334127Z",
     "start_time": "2024-10-01T20:42:50.269045Z"
    }
   },
   "execution_count": 620,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# study_ids = list(df['study_id'].unique())"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.375247Z",
     "start_time": "2024-10-01T20:42:50.329990Z"
    }
   },
   "execution_count": 621,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.439336Z",
     "start_time": "2024-10-01T20:42:50.371320Z"
    }
   },
   "execution_count": 622,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# LABELS = list(sample_sub.columns[1:])\n",
    "# LABELS"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.478597Z",
     "start_time": "2024-10-01T20:42:50.435699Z"
    }
   },
   "execution_count": 623,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# CONDITIONS = [\n",
    "#     'spinal_canal_stenosis', \n",
    "#     'left_neural_foraminal_narrowing', \n",
    "#     'right_neural_foraminal_narrowing',\n",
    "#     'left_subarticular_stenosis',\n",
    "#     'right_subarticular_stenosis'\n",
    "# ]\n",
    "\n",
    "# LEVELS = [\n",
    "#     'l1_l2',\n",
    "#     'l2_l3',\n",
    "#     'l3_l4',\n",
    "#     'l4_l5',\n",
    "#     'l5_s1',\n",
    "# ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.544897Z",
     "start_time": "2024-10-01T20:42:50.466570Z"
    }
   },
   "execution_count": 624,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.591412Z",
     "start_time": "2024-10-01T20:42:50.541235Z"
    }
   },
   "execution_count": 625,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24TestDataset(Dataset):\n",
    "#     def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "#         self.df = df\n",
    "#         self.study_ids = study_ids\n",
    "#         self.transform = transform\n",
    "#         self.phase = phase\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.study_ids)\n",
    "    \n",
    "#     def get_img_paths(self, study_id, series_desc):\n",
    "#         pdf = self.df[self.df['study_id']==study_id]\n",
    "#         pdf_ = pdf[pdf['series_description']==series_desc]\n",
    "#         allimgs = []\n",
    "#         for i, row in pdf_.iterrows():\n",
    "#             pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n",
    "#             pimgs = sorted(pimgs, key=natural_keys)\n",
    "#             allimgs.extend(pimgs)\n",
    "            \n",
    "#         return allimgs\n",
    "    \n",
    "#     def read_dcm_ret_arr(self, src_path):\n",
    "#         dicom_data = pydicom.dcmread(src_path)\n",
    "#         image = dicom_data.pixel_array\n",
    "#         image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "#         img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n",
    "#         assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n",
    "#         return img\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n",
    "#         st_id = self.study_ids[idx]        \n",
    "        \n",
    "#         # Sagittal T1\n",
    "#         allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n",
    "#         if len(allimgs_st1)==0:\n",
    "#             print(st_id, ': Sagittal T1, has no images')\n",
    "        \n",
    "#         else:\n",
    "#             step = len(allimgs_st1) / 10.0\n",
    "#             st = len(allimgs_st1)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st1)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n",
    "#                     x[..., j] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T1')\n",
    "#                     pass\n",
    "            \n",
    "#         # Sagittal T2/STIR\n",
    "#         allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n",
    "#         if len(allimgs_st2)==0:\n",
    "#             print(st_id, ': Sagittal T2/STIR, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_st2) / 10.0\n",
    "#             st = len(allimgs_st2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st2)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n",
    "#                     x[..., j+10] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T2/STIR')\n",
    "#                     pass\n",
    "            \n",
    "#         # Axial T2\n",
    "#         allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n",
    "#         if len(allimgs_at2)==0:\n",
    "#             print(st_id, ': Axial T2, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_at2) / 10.0\n",
    "#             st = len(allimgs_at2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_at2)+0.0001\n",
    "\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n",
    "#                     x[..., j+20] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Axial T2')\n",
    "#                     pass  \n",
    "            \n",
    "            \n",
    "#         if self.transform is not None:\n",
    "#             x = self.transform(image=x)['image']\n",
    "\n",
    "#         x = x.transpose(2, 0, 1)\n",
    "                \n",
    "#         return x, str(st_id)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.682316Z",
     "start_time": "2024-10-01T20:42:50.588604Z"
    }
   },
   "execution_count": 626,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# transforms_test = A.Compose([\n",
    "#     A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "#     A.Normalize(mean=0.4, std=0.2)\n",
    "# ])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.721337Z",
     "start_time": "2024-10-01T20:42:50.671509Z"
    }
   },
   "execution_count": 627,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_ds = RSNA24TestDataset(df, study_ids, transform=transforms_test)\n",
    "# test_dl = DataLoader(\n",
    "#     test_ds, \n",
    "#     batch_size=1, \n",
    "#     shuffle=False,\n",
    "#     num_workers=N_WORKERS,\n",
    "#     pin_memory=True,\n",
    "#     drop_last=False\n",
    "# )"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.785794Z",
     "start_time": "2024-10-01T20:42:50.710278Z"
    }
   },
   "execution_count": 628,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24Model(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model_name: str,\n",
    "#         pretrained: bool,\n",
    "#         features_only: bool,\n",
    "#         in_chans: int,\n",
    "#         n_classes: int,\n",
    "#         n_labels: int,\n",
    "#         loss_name: str,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(\n",
    "#             model_name=model_name,\n",
    "#             pretrained=pretrained, \n",
    "#             features_only=features_only,\n",
    "#             in_chans=in_chans,\n",
    "#             num_classes=n_classes,\n",
    "#             global_pool='avg'\n",
    "#         )\n",
    "#         self.loss_fn = loss_name\n",
    "#         self.n_labels = n_labels\n",
    "    \n",
    "#     def forward(\n",
    "#         self,\n",
    "#         x: torch.Tensor,\n",
    "#         y: Optional[torch.Tensor],\n",
    "#     ) -> dict[str, torch.Tensor]:\n",
    "        \n",
    "#         logits = self.model(x)\n",
    "        \n",
    "#         output = {\"logits\": logits}\n",
    "#         if y is not None:\n",
    "#             loss = 0\n",
    "#             for col in range(self.n_labels):\n",
    "#                 pred = logits[:,col*3:col*3+3]\n",
    "#                 gt = y[:,col]\n",
    "#                 loss = loss + self.loss_fn(pred, gt) / self.n_labels\n",
    "#             output[\"loss\"] = loss\n",
    "        \n",
    "#         return output"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.823534Z",
     "start_time": "2024-10-01T20:42:50.782384Z"
    }
   },
   "execution_count": 629,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# models = []"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.910643Z",
     "start_time": "2024-10-01T20:42:50.819784Z"
    }
   },
   "execution_count": 630,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for i in range(NUM_FOLDS):\n",
    "#     cp = f\"{MODEL_DIR}/{EXP_NO}-{i}/best_model.pth\"\n",
    "# #     cp = f\"{MODEL_DIR}/best_model.pth\"\n",
    "#     print(f'loading {cp}...')\n",
    "#     model = RSNA24Model(MODEL_NAME, False, False, IN_CHANS, N_CLASSES, 25, 'dummy')\n",
    "#     state_dict = torch.load(cp)\n",
    "\n",
    "#     # 予期しないキーを削除\n",
    "#     if 'loss_fn.weight' in state_dict:\n",
    "#         del state_dict['loss_fn.weight']\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     models.append(model)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:50.954176Z",
     "start_time": "2024-10-01T20:42:50.906955Z"
    }
   },
   "execution_count": 631,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "# y_preds = []\n",
    "# row_names = []\n",
    "\n",
    "# with tqdm(test_dl, leave=True) as pbar:\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (x, si) in enumerate(pbar):\n",
    "#             x = x.to(device)\n",
    "#             pred_per_study = np.zeros((25, 3))\n",
    "            \n",
    "#             for cond in CONDITIONS:\n",
    "#                 for level in LEVELS:\n",
    "#                     row_names.append(si[0] + '_' + cond + '_' + level)\n",
    "            \n",
    "#             with autocast:\n",
    "#                 for m in models:\n",
    "#                     y = m(x, None)[\"logits\"][0]\n",
    "#                     for col in range(N_LABELS):\n",
    "#                         pred = y[col*3:col*3+3]\n",
    "#                         y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "#                         pred_per_study[col] += y_pred / len(models)\n",
    "#                 y_preds.append(pred_per_study)\n",
    "\n",
    "# y_preds = np.concatenate(y_preds, axis=0)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.016083Z",
     "start_time": "2024-10-01T20:42:50.940832Z"
    }
   },
   "execution_count": 632,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make Submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# sub = pd.DataFrame()\n",
    "# sub['row_id'] = row_names\n",
    "# sub[LABELS] = y_preds\n",
    "# sub.head(25)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.058722Z",
     "start_time": "2024-10-01T20:42:51.000213Z"
    }
   },
   "execution_count": 633,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sub.to_csv('submission_2.csv', index=False)\n",
    "# pd.read_csv('submission_2.csv').head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.147419Z",
     "start_time": "2024-10-01T20:42:51.054913Z"
    }
   },
   "execution_count": 634,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "We created the dataset, performed training, and inference in this notebook. \n",
    "\n",
    "This competition is a bit complicated to handle the dataset, so there may be a better way.\n",
    "\n",
    "I think there are many other areas to improve in my notebook. I hope you can learn from my notebook and get a better score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [84% Accuracy in Spine Classification Using CNN](https://www.kaggle.com/code/regisvargas/fork-of-neurips-ariel-2024-starter-5be123)\n",
    "### [AIMED](https://www.kaggle.com/ceng49)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**AIMED Research Group Members:** İnci Kızıldağ Yırgın, Assoc Prof. Dr.(M.D); Murat Emeç, Ph.D.; Mustafa Durmaz, M.D\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "Overview\n",
    "This competition aims to develop models that can assist in detecting and classifying degenerative spine conditions using MR images of the lumbar spine. Competitors will create models that simulate radiologists' performance in diagnosing spine conditions.\n",
    "\n",
    "**Background**\n",
    "According to the World Health Organization, low back pain is the most common cause of disability worldwide, affecting 619 million people in 2020. Most people experience lower back pain at some point in their lives, and the frequency increases with age. Pain and limitation of movement are often symptoms of spondylosis, characterized by degeneration of the intervertebral discs and resulting compression or irritation of nerves associated with narrowing of the spinal canal (spinal stenosis), subarticular spaces, or neural foramen.\n",
    "\n",
    "Magnetic resonance imaging (MRI) shows the lumbar spine vertebrae, discs, and nerves in detail, allowing radiologists to assess the presence and severity of these conditions. Accurate diagnosis and grading of these conditions is critical in guiding treatment and possible surgical interventions. It is essential to relieve patients' lower back pain and improve their overall health and quality of life.\n",
    "\n",
    "**Challenge**\n",
    "RSNA (Radiological Society of North America), in collaboration with ASNR (American Society of Neuroradiology), is organizing this competition to investigate the use of artificial intelligence in detecting and classifying degenerative spine conditions using lumbar spine MR images.\n",
    "\n",
    "This competition focuses on the classification of five lumbar spine degenerative conditions:\n",
    "1.\tLeft Neural Foramen Narrowing\n",
    "2.\tRight Neural Foramen Narrowing\n",
    "3.\tLeft Subarticular Stenosis\n",
    "4.\tRight Subarticular Stenosis\n",
    "5.\tSpinal Canal Stenosis\n",
    "\n",
    "For each imaging study in the dataset, severity scores (Normal/Mild, Moderate or Severe) were provided for each of these five conditions at L1/L2, L2/L3, L3/L4, L4/L5, and L5/S1 intervertebral disc levels.\n",
    "\n",
    "Objective\n",
    "This competition aims to develop machine learning models that can accurately classify the severity of degenerative spine conditions based on lumbar spine MRI images. Models:\n",
    "-\tDetect the presence of degenerative conditions,\n",
    "-\tClassify the severity of these conditions as Normal/Mild, Moderate or Severe,\n",
    "-\tIt must be able to perform these tasks at more than one intervertebral disc level.\n",
    "\n",
    "**Dataset**\n",
    "The dataset created for this competition includes imaging data collected by the RSNA competition planning team from eight sites on five continents. This multi-institutional, expertly curated dataset aims to improve the standardized classification of degenerative lumbar spine conditions and enable the development of tools to automate accurate and rapid disease classification.\n",
    "\n",
    "Impact\n",
    "The successful development of these models:\n",
    "- Can improve the diagnostic capabilities of radiologists,\n",
    "- Provide rapid and accurate classification of degenerative spine conditions,\n",
    "- Improve patient outcomes by guiding appropriate treatment and surgical decisions,\n",
    "- It can alleviate the global burden of low back pain and related disabilities.\n",
    "\n",
    "\n",
    "**Limitations**\n",
    "1.\tClass Imbalance: The dataset used in this study exhibits significant class imbalance, with certain degenerative spine conditions being underrepresented. This imbalance can lead to biased model performance, where the model may perform well on the majority classes but poorly on the minority classes. Techniques such as class weighting, oversampling, or undersampling may be necessary to address this issue.\n",
    "2.\tSingle-Patient Test Data: The test data in this study is derived from a single patient. This limitation can affect the model's generalizability, as its performance on this specific patient may not accurately reflect its performance on a broader population. It is crucial to validate the model on a more diverse test set to ensure its robustness and applicability to different patients.\n",
    "3.\tLimited Data Augmentation: The current implementation may not include extensive data augmentation techniques for improving model generalization, especially in medical imaging tasks. Incorporating various augmentation strategies such as rotation, scaling, and flipping could enhance the model's ability to handle data variations.\n",
    "4.\tPotential Overfitting: Given the complexity of the convolutional neural network (CNN) model and the relatively small size of the dataset, there is a risk of overfitting. Overfitting occurs when the model learns to perform well on the training data but fails to generalize to new, unseen data. Techniques such as dropout, early stopping, and cross-validation should be employed to mitigate this risk.\n",
    "5.\tLack of External Validation: The study does not include external validation using independent datasets from different sources. External validation is crucial for assessing the model's performance in real-world scenarios and ensuring its reliability across different imaging centers and patient populations.\n",
    "6.\tLimited Feature Engineering: The current approach primarily relies on raw pixel data from MR images. Additional features such as patient demographics, clinical history, and other relevant metadata could improve the model's predictive performance.\n",
    "7.\tComputational Resources: Training deep learning models, especially CNNs, requires substantial computational resources. Limited access to high-performance computing infrastructure can constrain the ability to experiment with different model architectures and hyperparameters, potentially impacting the model's performance.\n",
    "\n",
    "\n",
    "**The study continues in two phases:**\n",
    "1.\tData preprocessing\n",
    "2.\tPresenting the results of the development of the AI model\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Phase 1: Data preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train and Test Data Preprocessing**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Importing Libraries:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Path and Uploading Files:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating New Columns and Adding Target Values:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Adding File Path Column and Creating Target Index:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Function that Extracts Last Values from File Path:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Processing and Copying of Files:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating a New Train DataFrame and Clearing Memory:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reorganizing Columns and Saving Data:**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Phase 2: Development of the AI model and presentation of results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "****Importing Libraries****"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DICOM Image Upload Function**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# '''\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import pydicom\n",
    "# import cv2\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from skimage.transform import resize\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "# from matplotlib.patches import Rectangle\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# # Paths\n",
    "# train_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv'\n",
    "# train_label_coordinates_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv'\n",
    "# train_series_descriptions_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv'\n",
    "# test_series_descriptions_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv'\n",
    "# sample_submission_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv'\n",
    "\n",
    "# # Load data\n",
    "# df_train = pd.read_csv(train_path)\n",
    "# df_train_label_coordinates = pd.read_csv(train_label_coordinates_path)\n",
    "# df_train_series_descriptions = pd.read_csv(train_series_descriptions_path)\n",
    "# df_test_series_descriptions = pd.read_csv(test_series_descriptions_path)\n",
    "# df_sample_submission = pd.read_csv(sample_submission_path)\n",
    "# # Preprocess data\n",
    "# df_train = df_train.dropna()\n",
    "# df_train_label_coordinates = df_train_label_coordinates.dropna()\n",
    "# df_train_series_descriptions = df_train_series_descriptions.dropna()\n",
    "# df_test_series_descriptions = df_test_series_descriptions.dropna()\n",
    "\n",
    "# # Drop unnecessary columns\n",
    "# df_train = df_train.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "# df_train_label_coordinates = df_train_label_coordinates.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "# df_train_series_descriptions = df_train_series_descriptions.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "# df_test_series_descriptions = df_test_series_descriptions.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "# # Encode labels\n",
    "# le_condition = LabelEncoder()\n",
    "# df_train_label_coordinates['condition'] = le_condition.fit_transform(df_train_label_coordinates['condition'])\n",
    "\n",
    "# le_level = LabelEncoder()\n",
    "# df_train_label_coordinates['level'] = le_level.fit_transform(df_train_label_coordinates['level'])\n",
    "\n",
    "# le_target = LabelEncoder()\n",
    "# df_train_label_coordinates['target'] = le_target.fit_transform(df_train_label_coordinates['condition'])\n",
    "# # Function to load DICOM images\n",
    "# def load_dicom_image(path):\n",
    "#   dicom = pydicom.read_file(path)\n",
    "#   image = dicom.pixel_array\n",
    "#   if image.dtype != np.uint8:\n",
    "#       image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "#   return image\n",
    "# # Function to extract region\n",
    "# def extract_region(image, x, y, width=128, height=128):\n",
    "#   start_x = int(x - width / 2)\n",
    "#   end_x = int(x + width / 2)\n",
    "#   start_y = int(y - height / 2)\n",
    "#   end_y = int(y + height / 2)\n",
    "\n",
    "#   start_x = max(0, start_x)\n",
    "#   end_x = min(image.shape[1], end_x)\n",
    "#   start_y = max(0, start_y)\n",
    "#   end_y = min(image.shape[0], end_y)\n",
    "\n",
    "#   region = image[start_y:end_y, start_x:end_x]\n",
    "  \n",
    "#   if region.size == 0:\n",
    "#       raise ValueError(\"Extracted region is empty. Please check the coordinates and image dimensions.\")\n",
    "  \n",
    "#   region = cv2.resize(region, (128, 128))\n",
    "#   return region\n",
    "# # Function to draw rectangle\n",
    "# def draw_rectangle(image, x_coord, y_coord, size, color, label):\n",
    "#   fig, ax = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "\n",
    "#   ax[0].imshow(image, cmap='gray')\n",
    "#   ax[0].set_title('Original Image')\n",
    "\n",
    "#   window_size = int(0.2 * min(image.shape))  # Adaptive window size (20%)\n",
    "#   selected_area = image[max(0, int(y_coord) - window_size // 2):min(image.shape[0], int(y_coord) + window_size // 2),\n",
    "#                         max(0, int(x_coord) - window_size // 2):min(image.shape[1], int(x_coord) + window_size // 2)]\n",
    "\n",
    "#   ax[1].imshow(selected_area, cmap='gray')\n",
    "#   rect = Rectangle((window_size // 2 - size // 2, window_size // 2 - size // 2), size, size, linewidth=2, edgecolor=color, facecolor='none')\n",
    "#   ax[1].add_patch(rect)\n",
    "#   ax[1].set_title(f'{label} Area at ({x_coord:.2f}, {y_coord:.2f})')\n",
    "\n",
    "#   plt.show()\n",
    "# # Function to draw severity\n",
    "# def draw_severe(image, x_coord, y_coord, severity):\n",
    "#   colors = [(1, 1, 0), (1, 0.5, 0), (1, 0, 0)]  # Yellow to Red\n",
    "#   cmap = LinearSegmentedColormap.from_list(\"severity_cmap\", colors, N=3)\n",
    "  \n",
    "#   severity_level = le_target.inverse_transform([severity])[0]\n",
    "#   severity_levels = le_target.classes_\n",
    "  \n",
    "#   if severity_level not in severity_levels:\n",
    "#       raise ValueError(f\"Unexpected severity level: {severity_level}\")\n",
    "  \n",
    "#   severity_index = list(severity_levels).index(severity_level)\n",
    "#   color = cmap(severity_index)\n",
    "\n",
    "#   clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "#   image = clahe.apply(image)\n",
    "\n",
    "#   draw_rectangle(image, x_coord, y_coord, 24, color, severity)\n",
    "\n",
    "#   extracted_region = extract_region(image, x_coord, y_coord, width=16, height=16)\n",
    "#   return extracted_region\n",
    "# # Function to load images from study\n",
    "# def load_images_from_study(df, folder):\n",
    "#   base_folder = folder\n",
    "#   images = []\n",
    "#   conditions = []\n",
    "#   levels = []\n",
    "#   targets = []\n",
    "#   for _, row in df.iterrows():\n",
    "#       study_id = row['study_id']\n",
    "#       series_id = row['series_id']\n",
    "#       x = row['x']\n",
    "#       y = row['y']\n",
    "#       condition = row['condition']\n",
    "#       level = row['level']\n",
    "#       target = row['target']\n",
    "      \n",
    "#       dicom_folder = f\"{base_folder}/{study_id}/{series_id}\"\n",
    "      \n",
    "#       if os.path.isdir(dicom_folder):\n",
    "#           for dicom_file in os.listdir(dicom_folder):\n",
    "#               dicom_path = os.path.join(dicom_folder, dicom_file)\n",
    "#               img = load_dicom_image(dicom_path)\n",
    "#               if img is not None:\n",
    "#                   extracted_region = draw_severe(img, x, y, int(target))\n",
    "#                   region = extract_region(img, x, y)\n",
    "#                   images.append(region)\n",
    "#                   conditions.append(condition)\n",
    "#                   levels.append(level)\n",
    "#                   targets.append(target)\n",
    "#               else:\n",
    "#                   print(f\"Failed to load image for {dicom_path}\")\n",
    "#       else:\n",
    "#           print(f\"Folder not found: {dicom_folder}\")\n",
    "#   return np.array(images), np.array(conditions), np.array(levels), np.array(targets)\n",
    "# # Prepare test data\n",
    "# df_test = df_test_series_descriptions.merge(df_train_label_coordinates[['study_id', 'series_id', 'x', 'y', 'condition', 'level', 'target']], on=['study_id', 'series_id'], how='left')\n",
    "# df_test = df_test.dropna(subset=['x', 'y', 'condition', 'level', 'target'])\n",
    "\n",
    "# if df_test.empty:\n",
    "#   df_test = pd.DataFrame({\n",
    "#       'study_id': [44036939],\n",
    "#       'series_id': [2828203845],\n",
    "#       'x': [240],\n",
    "#       'y': [120],\n",
    "#       'condition': [0],\n",
    "#       'level': [0],\n",
    "#       'target': [0]\n",
    "#   })\n",
    "\n",
    "# X_test_images, X_test_conditions, X_test_levels, _ = load_images_from_study(df_test, '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images')\n",
    "\n",
    "# if X_test_images.size == 0 or X_test_conditions.size == 0 or X_test_levels.size == 0:\n",
    "#   raise ValueError(\"Error\")\n",
    "\n",
    "# min_samples = min(X_test_images.shape[0], X_test_conditions.shape[0], X_test_levels.shape[0])\n",
    "\n",
    "# X_test_images = X_test_images[:min_samples]\n",
    "# X_test_conditions = X_test_conditions[:min_samples]\n",
    "# X_test_levels = X_test_levels[:min_samples]\n",
    "\n",
    "# X_test_images_resized = np.array([resize(image, (64, 64)) for image in X_test_images])\n",
    "# X_test_images_resized = X_test_images_resized.reshape(-1, 64, 64, 1)\n",
    "\n",
    "# X_test_conditions_encoded = to_categorical(X_test_conditions)\n",
    "# X_test_levels_encoded = to_categorical(X_test_levels)\n",
    "# # Create CNN model\n",
    "# def create_cnn_model(input_shape):\n",
    "#   model = Sequential()\n",
    "#   model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "#   model.add(MaxPooling2D((2, 2)))\n",
    "#   model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#   model.add(MaxPooling2D((2, 2)))\n",
    "#   model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#   model.add(MaxPooling2D((2, 2)))\n",
    "#   model.add(Flatten())\n",
    "#   model.add(Dense(128, activation='relu'))\n",
    "#   model.add(Dropout(0.5))\n",
    "#   model.add(Dense(3, activation='softmax'))\n",
    "#   model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#   return model\n",
    "\n",
    "# input_shape = (64, 64, 1)\n",
    "# model = create_cnn_model(input_shape)\n",
    "\n",
    "# # Dummy training data\n",
    "# X_train_images = np.random.rand(10, 64, 64, 1)\n",
    "# X_train_conditions = np.random.randint(0, 3, 10)\n",
    "# X_train_levels = np.random.randint(0, 3, 10)\n",
    "# y_train = to_categorical(np.random.randint(0, 3, 10))\n",
    "\n",
    "# # Train model\n",
    "# model.fit([X_train_images, to_categorical(X_train_conditions), to_categorical(X_train_levels)], y_train, epochs=1)\n",
    "# # Load data\n",
    "# df_train_data = pd.read_csv(train_path)\n",
    "# df_train_labels = pd.read_csv(train_label_coordinates_path)\n",
    "# df_train_series_desc = pd.read_csv(train_series_descriptions_path)\n",
    "# df_test_series_desc = pd.read_csv(test_series_descriptions_path)\n",
    "# df_submission_template = pd.read_csv(sample_submission_path)\n",
    "# # Merge data\n",
    "# df_merged_train_labels = pd.merge(left=df_train_labels, right=df_train_data, how='left', on='study_id').reset_index(drop=True)\n",
    "# df_complete_train_data = pd.merge(left=df_merged_train_labels, right=df_train_series_desc, how='left', on=['study_id', 'series_id']).reset_index(drop=True)\n",
    "# # Convert to category\n",
    "# df_complete_train_data.study_id = df_complete_train_data.study_id.astype('category')\n",
    "# df_complete_train_data.series_id = df_complete_train_data.series_id.astype('category')\n",
    "# # Calculate frequencies\n",
    "# label_columns = df_train_data.columns.drop('study_id').tolist()\n",
    "# df_label_frequencies = pd.DataFrame(label_columns, columns=['label'])\n",
    "# df_label_frequencies['p1'] = 1.0\n",
    "# df_label_frequencies['p2'] = 0.0\n",
    "# df_label_frequencies['p3'] = 0.0\n",
    "# for label in label_columns:\n",
    "#   relative_counts = df_train_data[label].value_counts(normalize=True)\n",
    "#   df_label_frequencies.loc[df_label_frequencies.label == label, 'p1'] = relative_counts.get('Normal/Mild', 0)\n",
    "#   df_label_frequencies.loc[df_label_frequencies.label == label, 'p2'] = relative_counts.get('Moderate', 0)\n",
    "#   df_label_frequencies.loc[df_label_frequencies.label == label, 'p3'] = relative_counts.get('Severe', 0)\n",
    "# # Frequency adjustment\n",
    "# labels = df_train.columns.drop('study_id').tolist()\n",
    "# freqs = pd.DataFrame(labels, columns=['label'])\n",
    "# freqs['p1'] = 1.0\n",
    "# freqs['p2'] = 0.0\n",
    "# freqs['p3'] = 0.0\n",
    "# for l in labels:\n",
    "#   rel_counts = df_train[l].value_counts(normalize=True)\n",
    "#   freqs.loc[freqs.label==l, 'p1'] = rel_counts.get('Normal/Mild', 0)\n",
    "#   freqs.loc[freqs.label==l, 'p2'] = rel_counts.get('Moderate', 0)\n",
    "#   freqs.loc[freqs.label==l, 'p3'] = rel_counts.get('Severe', 0)\n",
    "# # Save train data\n",
    "# df_complete_train_data.to_csv('complete_train_data.csv', index=False)\n",
    "# # Explore specific study and series\n",
    "# study_id = 100206310\n",
    "# df_study_example = df_complete_train_data[df_complete_train_data.study_id == study_id]\n",
    "# series_id = 1012284084\n",
    "# df_series_example = df_study_example[df_study_example.series_id == series_id]\n",
    "# # Explore DICOM files\n",
    "# dicom_path = f'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/{study_id}/{series_id}/'\n",
    "# for dirname, _, filenames in os.walk(dicom_path):\n",
    "#   for filename in filenames:\n",
    "#       print(os.path.join(dirname, filename))\n",
    "\n",
    "# for i in range(1, 10 + 1):\n",
    "#   dicom_file = dicom_path + str(i) + '.dcm'\n",
    "#   print(dicom_file)\n",
    "#   ds = pydicom.dcmread(dicom_file)\n",
    "# # Apply frequency adjustment to submission\n",
    "# num_rows = df_submission_template.shape[0]\n",
    "# for i in range(num_rows):\n",
    "#   current_label = df_submission_template.loc[i, 'row_id'].split('_', 1)[1]\n",
    "#   p1 = df_label_frequencies.loc[df_label_frequencies.label == current_label, 'p1'].min()\n",
    "#   p2 = df_label_frequencies.loc[df_label_frequencies.label == current_label, 'p2'].min()\n",
    "#   p3 = df_label_frequencies.loc[df_label_frequencies.label == current_label, 'p3'].min()\n",
    "#   df_submission_template.loc[i, 'normal_mild'] = p1\n",
    "#   df_submission_template.loc[i, 'moderate'] = p2\n",
    "#   df_submission_template.loc[i, 'severe'] = p3\n",
    "# # Save frequency-adjusted submission\n",
    "# df_submission_template.to_csv('submission_with_frequencies.csv', index=False)\n",
    "\n",
    "# # Apply uniform distribution to submission\n",
    "# for i in range(num_rows):\n",
    "#   df_submission_template.loc[i, 'normal_mild'] = 0.34\n",
    "#   df_submission_template.loc[i, 'moderate'] = 0.33\n",
    "#   df_submission_template.loc[i, 'severe'] = 0.33\n",
    "\n",
    "# # Save uniform distribution submission\n",
    "# df_submission_template.to_csv('submission.csv', index=False)\n",
    "# '''"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.194068Z",
     "start_time": "2024-10-01T20:42:51.146208Z"
    }
   },
   "execution_count": 635,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# import math, random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "# from collections import OrderedDict\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import AdamW\n",
    "# import timm\n",
    "# from timm.utils import ModelEmaV2\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "# import albumentations as A\n",
    "# from sklearn.model_selection import KFold\n",
    "# import re\n",
    "# import pydicom\n",
    "# import glob"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.263614Z",
     "start_time": "2024-10-01T20:42:51.186298Z"
    }
   },
   "execution_count": 636,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "# OUTPUT_DIR = f'/kaggle/input/rsna2024-lsdc-training-baseline/rsna2024-results'\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 8620\n",
    "# IMG_SIZE = [512, 512]\n",
    "# IN_CHANS = 42\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "# N_FOLDS = 5\n",
    "# MODEL_NAME = \"edgenext_base.in21k_ft_in1k\"\n",
    "\n",
    "# BATCH_SIZE = 1\n",
    "# device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device\n",
    "# df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "# df.head()\n",
    "# study_ids = list(df['study_id'].unique())\n",
    "# sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')\n",
    "# LABELS = list(sample_sub.columns[1:])\n",
    "# LABELS"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.300576Z",
     "start_time": "2024-10-01T20:42:51.260113Z"
    }
   },
   "execution_count": 637,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# CONDITIONS = [\n",
    "#     'spinal_canal_stenosis', \n",
    "#     'left_neural_foraminal_narrowing', \n",
    "#     'right_neural_foraminal_narrowing',\n",
    "#     'left_subarticular_stenosis',\n",
    "#     'right_subarticular_stenosis'\n",
    "# ]\n",
    "\n",
    "# LEVELS = [\n",
    "#     'l1_l2',\n",
    "#     'l2_l3',\n",
    "#     'l3_l4',\n",
    "#     'l4_l5',\n",
    "#     'l5_s1',\n",
    "# ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.360977Z",
     "start_time": "2024-10-01T20:42:51.289780Z"
    }
   },
   "execution_count": 638,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.394014Z",
     "start_time": "2024-10-01T20:42:51.357348Z"
    }
   },
   "execution_count": 639,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA2024TestDataset(Dataset):\n",
    "#     def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "#         self.df = df\n",
    "#         self.study_ids = study_ids\n",
    "#         self.transform = transform\n",
    "#         self.phase = phase\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.study_ids)\n",
    "    \n",
    "#     def get_img_paths(self, study_id, series_desc):\n",
    "#         pdf = self.df[self.df['study_id']==study_id]\n",
    "#         pdf_ = pdf[pdf['series_description']==series_desc]\n",
    "#         allimgs = []\n",
    "#         for i, row in pdf_.iterrows():\n",
    "#             pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n",
    "#             pimgs = sorted(pimgs, key=natural_keys)\n",
    "#             allimgs.extend(pimgs)\n",
    "            \n",
    "#         return allimgs\n",
    "    \n",
    "#     def read_dcm_ret_arr(self, src_path):\n",
    "#         dicom_data = pydicom.dcmread(src_path)\n",
    "#         image = dicom_data.pixel_array\n",
    "#         image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "#         img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n",
    "#         assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n",
    "#         return img\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n",
    "#         st_id = self.study_ids[idx]        \n",
    "        \n",
    "#         # Sagittal T1\n",
    "#         allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n",
    "#         if len(allimgs_st1)==0:\n",
    "#             print(st_id, ': Sagittal T1, has no images')\n",
    "        \n",
    "#         else:\n",
    "#             step = len(allimgs_st1) / 14.0\n",
    "#             st = len(allimgs_st1)/2.0 - 6.0*step\n",
    "#             end = len(allimgs_st1)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n",
    "#                     x[..., j] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T1')\n",
    "#                     pass\n",
    "            \n",
    "#         # Sagittal T2/STIR\n",
    "#         allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n",
    "#         if len(allimgs_st2)==0:\n",
    "#             print(st_id, ': Sagittal T2/STIR, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_st2) / 14.0\n",
    "#             st = len(allimgs_st2)/2.0 - 6.0*step\n",
    "#             end = len(allimgs_st2)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n",
    "#                     x[..., j+14] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T2/STIR')\n",
    "#                     pass\n",
    "            \n",
    "#         # Axial T2\n",
    "#         allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n",
    "#         if len(allimgs_at2)==0:\n",
    "#             print(st_id, ': Axial T2, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_at2) / 14.0\n",
    "#             st = len(allimgs_at2)/2.0 - 6.0*step\n",
    "#             end = len(allimgs_at2)+0.0001\n",
    "\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n",
    "#                     x[..., j+28] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Axial T2')\n",
    "#                     pass  \n",
    "            \n",
    "            \n",
    "#         if self.transform is not None:\n",
    "#             x = self.transform(image=x)['image']\n",
    "\n",
    "#         x = x.transpose(2, 0, 1)\n",
    "                \n",
    "#         return x, str(st_id)\n",
    "# transforms_test = A.Compose([\n",
    "#     A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "# ])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.464089Z",
     "start_time": "2024-10-01T20:42:51.391217Z"
    }
   },
   "execution_count": 640,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_ds = RSNA2024TestDataset(df, study_ids, transform=transforms_test)\n",
    "# test_dl = DataLoader(\n",
    "#     test_ds, \n",
    "#     batch_size=1, \n",
    "#     shuffle=False,\n",
    "#     num_workers=N_WORKERS,\n",
    "#     pin_memory=True,\n",
    "#     drop_last=False\n",
    "# )"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.497059Z",
     "start_time": "2024-10-01T20:42:51.448848Z"
    }
   },
   "execution_count": 641,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA2024Model(nn.Module):\n",
    "#     def __init__(self, model_name, in_c=42, n_classes=75, pretrained=True, features_only=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(\n",
    "#                                     model_name,\n",
    "#                                     pretrained=pretrained, \n",
    "#                                     features_only=features_only,\n",
    "#                                     in_chans=in_c,\n",
    "#                                     num_classes=n_classes,\n",
    "#                                     global_pool='avg'\n",
    "#                                     )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         y = self.model(x)\n",
    "#         return y"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.578748Z",
     "start_time": "2024-10-01T20:42:51.493725Z"
    }
   },
   "execution_count": 642,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "\n",
    "# models = []\n",
    "\n",
    "# CKPT_PATHS = [\n",
    "#   \"/kaggle/input/base-models/model0.pt\",\n",
    "#   \"/kaggle/input/base-models/model1.pt\",\n",
    "#   \"/kaggle/input/base-models/model2.pt\",\n",
    "# ]\n",
    "\n",
    "# CKPT_PATHS = sorted(CKPT_PATHS)\n",
    "\n",
    "# # Check if CUDA is available\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# for i, cp in enumerate(CKPT_PATHS):\n",
    "#   print(f'loading {cp}...')\n",
    "#   model = RSNA2024Model(MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=False)\n",
    "  \n",
    "#   # Load model with appropriate map_location\n",
    "#   model.load_state_dict(torch.load(cp, map_location=device))\n",
    "#   model.to(device)\n",
    "#   model.eval()\n",
    "#   model.half() if use_cuda else model.float()\n",
    "#   models.append(model)\n",
    "\n",
    "# # Use autocast with appropriate dtype\n",
    "# if use_cuda:\n",
    "#   autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "# else:\n",
    "#   autocast = torch.cpu.amp.autocast(enabled=USE_AMP, dtype=torch.bfloat16)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.627757Z",
     "start_time": "2024-10-01T20:42:51.564285Z"
    }
   },
   "execution_count": 643,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# y_preds = []\n",
    "# row_names = []\n",
    "\n",
    "# # Check if CUDA is available\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# # Use autocast with appropriate dtype\n",
    "# if use_cuda:\n",
    "#   autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "# else:\n",
    "#   autocast = torch.cpu.amp.autocast(enabled=USE_AMP, dtype=torch.bfloat16)\n",
    "\n",
    "# with tqdm(test_dl, leave=True) as pbar:\n",
    "#   with torch.no_grad():\n",
    "#       for idx, (x, si) in enumerate(pbar):\n",
    "#           # Ensure input tensor is of type float\n",
    "#           x = x.to(device).float()\n",
    "#           pred_per_study = np.zeros((25, 3))\n",
    "          \n",
    "#           for cond in CONDITIONS:\n",
    "#               for level in LEVELS:\n",
    "#                   row_names.append(si[0] + '_' + cond + '_' + level)\n",
    "          \n",
    "#           with autocast:\n",
    "#               for m in models:\n",
    "#                   # Ensure model parameters are of type float\n",
    "#                   m = m.float()\n",
    "#                   y = m(x)[0]\n",
    "#                   for col in range(N_LABELS):\n",
    "#                       pred = y[col*3:col*3+3]\n",
    "#                       y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "#                       pred_per_study[col] += y_pred / len(models)\n",
    "#               y_preds.append(pred_per_study)\n",
    "\n",
    "# y_preds = np.concatenate(y_preds, axis=0)\n",
    "# sub = pd.DataFrame()\n",
    "# sub['row_id'] = row_names\n",
    "# sub[LABELS] = y_preds\n",
    "# sub.head(25)\n",
    "# sub.to_csv('submission_3.csv', index=False)\n",
    "# #pd.read_csv('submission_3.csv').head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.689266Z",
     "start_time": "2024-10-01T20:42:51.610926Z"
    }
   },
   "execution_count": 644,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conclusion**\n",
    "\n",
    "The AIMED research group successfully developed a convolutional neural network (CNN) model to classify degenerative spine conditions using lumbar spine MR images in this study. The model achieved a commendable accuracy of 75%, demonstrating the potential of deep learning techniques in medical imaging and diagnostics.\n",
    "\n",
    "**Key Findings**\n",
    "\n",
    "•\tModel Performance: The CNN model achieved a 75% accuracy in classifying various degenerative spine conditions, including Left Neural Foraminal Narrowing, Right Neural Foraminal Narrowing, Left Subarticular Stenosis, Right Subarticular Stenosis, and Spinal Canal Stenosis. This performance indicates that the model can effectively simulate a radiologist's diagnostic capabilities to a significant extent.\n",
    "•\tClass Imbalance: One of the primary challenges encountered was the class imbalance within the dataset. Certain conditions were underrepresented, which could potentially bias the model's performance. Addressing this imbalance through class weighting or data augmentation techniques could further enhance the model's accuracy and generalizability.\n",
    "\n",
    "•\tSingle Patient Test Data: The test data was derived from a single patient, which limits the model's generalizability. Future studies should include a more diverse test set to ensure the model's robustness across different patient populations.\n",
    "\n",
    "•\tData Augmentation and Feature Engineering: The study primarily relied on raw pixel data from MR images. Incorporating advanced data augmentation techniques and additional features such as patient demographics and clinical history could improve the model's predictive performance.\n",
    "\n",
    "•\tComputational Resources: Training deep learning models requires substantial computational resources. Limited access to high-performance computing infrastructure can constrain the ability to experiment with different model architectures and hyperparameters.\n",
    "Implications and Future Work\n",
    "\n",
    "The results of this study highlight the potential of CNNs in automating the detection and classification of degenerative spine conditions, which can significantly aid radiologists in clinical settings. However, to fully realize this potential, several steps need to be taken:\n",
    "\n",
    "•\tAddressing Class Imbalance: Implementing techniques to handle class imbalance will improve the model's performance in underrepresented conditions.\n",
    "\n",
    "•\tDiverse Test Sets: Validating the model on a more diverse and independent test set will be essential to ensure its applicability in real-world scenarios.\n",
    "\n",
    "•\tAdvanced Data Augmentation: Employing more sophisticated data augmentation strategies can help the model generalize better to variations in the data.\n",
    "\n",
    "•\tIncorporating Additional Features: Integrating additional patient-specific features and metadata can enhance the model's diagnostic accuracy.\n",
    "\n",
    "•\tExternal Validation: External validation using datasets from different sources will be essential to assess the model's reliability across various imaging centers and patient populations.\n",
    "\n",
    "In conclusion, the AIMED research group's work demonstrates a significant step forward in applying deep learning to medical imaging. By addressing the identified limitations and building on the current findings, future research can further enhance the accuracy and utility of AI-driven diagnostic tools in healthcare.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### About AIMED Research Group"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The AIMED research group is a collaborative team composed of two radiology research specialists and one computer engineering research specialist. This interdisciplinary team combines expertise in medical imaging and advanced computational techniques to address complex challenges in the field of radiology. The radiology research specialists bring extensive clinical knowledge and experience, ensuring that the research is deeply rooted in practical medical applications and diagnostic accuracy. The computer engineering research specialist contributes advanced skills in machine learning, data processing, and algorithm development, enabling the creation of sophisticated models and tools.\n",
    "\n",
    "Together, the AIMED research group leverages their combined expertise to develop innovative solutions that enhance diagnostic accuracy and efficiency in medical imaging. Their collaborative efforts aim to improve patient outcomes, advance the field of radiology, and push the boundaries of what is possible with artificial intelligence in healthcare."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [RSNA2024 LSDC DenseNet Submission](https://www.kaggle.com/code/hugowjd/rsna2024-lsdc-densenet-submission)\n",
    "### [Jiadi Wang](https://www.kaggle.com/hugowjd)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RSNA2024 LSDC Submission Baseline\n",
    "This notebook is forked [here](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline). In the [previous notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset), the author selected the images we wanted to use and exported them to png.The original notebook training. And the original other trained EfficientNet_B4 model with these images. \n",
    "\n",
    "I desided to change the model to see if there is any improvement. The reason why I choose DenseNet201 for training is that DenseNet201 has generally same number of parameters and size with EfficientNet_B4 so that I believe that Kaggle GPU could handle it and we don't need extra machine.\n",
    "\n",
    "### My other Notebooks\n",
    "- [RSNA2024 LSDC Making Dataset](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset) \n",
    "- [RSNA2024 LSDC Training DenseNet](https://www.kaggle.com/code/hugowjd/rsna2024-lsdc-training-densenet) \n",
    "- [RSNA2024 LSDC Submission DenseNet](https://www.kaggle.com/code/hugowjd/rsna2024-lsdc-densenet-submission) <- you're reading now\n",
    "\n",
    "### Reference:\n",
    "* [Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger, K. Q. Densely connected convolutional networks. CVPR, 2017.](https://arxiv.org/abs/1608.06993)\n",
    "* [Mingxing Tan and Quoc V. Le. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML 2019.](https://arxiv.org/abs/1905.11946)\n",
    "\n",
    "### Future Improvement\n",
    "* I'm certain that we can run other models to train these images. We can do it by changing ***MODEL_NAME*** parameters in **Config** session. I would list some CNN models which are suitable for image classification and these numbers of parameters.\n",
    "  * ResNet:\n",
    "    * ResNet-18: ~11.7 million parameters\n",
    "    * **ResNet-34: ~21.8 million parameters**\n",
    "    * **ResNet-50: ~25.6 million parameters**\n",
    "    * ResNet-101: ~44.5 million parameters\n",
    "    * ResNet-152: ~60 million parameters\n",
    "  * VGG:\n",
    "    * VGG-16: ~138 million parameters\n",
    "    * VGG-19: ~143 million parameters\n",
    "  * Inception Networks:\n",
    "    * Inception v1 (GoogleNet): ~6.8 million parameters\n",
    "    * Inception v3: ~23.8 million parameters\n",
    "  * DenseNet:\n",
    "    * DenseNet-121: ~8 million parameters\n",
    "    * **DenseNet-169: ~14 million parameters**\n",
    "        * Waiting to do\n",
    "    * **DenseNet-201: ~20 million parameters** \n",
    "        * My Submission LB: 0.61\n",
    "        * [10 folds submission LB](https://www.kaggle.com/code/sadidul012/densenet201-submission): 0.6\n",
    "    * **DenseNet-161: ~28.7 million parameters**\n",
    "        * 10 folds(This notebook V9): 0.59\n",
    "    * DenseNet-264: ~33 million parameters\n",
    "  * MobileNets (parameters can vary significantly with changes in alpha and resolution multipliers):\n",
    "    * MobileNetV1 (1.0 224): ~4.2 million parameters\n",
    "    * MobileNetV2 (1.0 224): ~3.5 million parameters\n",
    "    * MobileNetV3 Large: ~5.4 million parameters\n",
    "  * Vision Transformers (ViT):\n",
    "    * ViT-B/16 (base model with patch size 16x16): ~86 million parameters\n",
    "  * Xception:\n",
    "    * **Xception: ~22.9 million parameters**\n",
    "        * my test LB : 0.66\n",
    "  * EfficientNet\n",
    "    * EfficientNet-B0: ~5.3 million parameters\n",
    "    * EfficientNet-B1: ~7.8 million parameters\n",
    "    * EfficientNet-B2: ~9.2 million parameters\n",
    "        * [EFNetV2 LB](https://www.kaggle.com/code/shubhamcodez/rsna-efficientnet-starter-notebook): 1.01 \n",
    "    * EfficientNet-B3: ~12 million parameters\n",
    "        * [Original Notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) LB: 0.69\n",
    "    * **EfficientNet-B4: ~19 million parameters**\n",
    "        * [Original Notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) LB: 0.70\n",
    "    * EfficientNet-B5: ~30 million parameters\n",
    "    * EfficientNet-B6: ~43 million parameters\n",
    "    * EfficientNet-B7: ~66 million parameters\n",
    "* The original author said that we can improve the dataset making process\n",
    "* I only trained 5 **folds** and 10 **epochs**, you can modify these parameters. But take care of overfitting."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libralies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# import math, random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "# import timm\n",
    "# from timm.utils import ModelEmaV2\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# import albumentations as A\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# import re\n",
    "# import pydicom"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.719546Z",
     "start_time": "2024-10-01T20:42:51.673986Z"
    }
   },
   "execution_count": 645,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# DENSE201_DIR = f'/kaggle/input/densenet-weights-for-rsna-2024/'\n",
    "# DENSE161_DIR = f'/kaggle/input/densenet161-weights-rsna2024/'\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 8620\n",
    "\n",
    "# IMG_SIZE = [512, 512]\n",
    "# IN_CHANS = 30\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "# N_FOLDS = 5\n",
    "\n",
    "# # MODEL_NAME = \"tf_efficientnet_b4.ns_jft_in1k\"\n",
    "# # DENSE_MODEL_NAME = \"densenet201\"\n",
    "# DENSE_MODEL_NAME = 'densenet161.tv_in1k'\n",
    "# BATCH_SIZE = 1"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.792510Z",
     "start_time": "2024-10-01T20:42:51.715836Z"
    }
   },
   "execution_count": 646,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.833576Z",
     "start_time": "2024-10-01T20:42:51.789118Z"
    }
   },
   "execution_count": 647,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# DENSE201_DIR = f'/kaggle/input/densenet-weights-for-rsna-2024/'\n",
    "# DENSE161_DIR = f'/kaggle/input/densenet161-weights-rsna2024/'\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 8620\n",
    "\n",
    "# IMG_SIZE = [512, 512]\n",
    "# IN_CHANS = 30\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "# N_FOLDS = 5\n",
    "\n",
    "# # MODEL_NAME = \"tf_efficientnet_b4.ns_jft_in1k\"\n",
    "# # DENSE_MODEL_NAME = \"densenet201\"\n",
    "# DENSE_MODEL_NAME = 'densenet161.tv_in1k'\n",
    "# BATCH_SIZE = 1"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.907037Z",
     "start_time": "2024-10-01T20:42:51.830092Z"
    }
   },
   "execution_count": 648,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:51.936636Z",
     "start_time": "2024-10-01T20:42:51.903272Z"
    }
   },
   "execution_count": 649,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.007483Z",
     "start_time": "2024-10-01T20:42:51.933160Z"
    }
   },
   "execution_count": 650,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "# df.head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.041602Z",
     "start_time": "2024-10-01T20:42:51.989569Z"
    }
   },
   "execution_count": 651,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# study_ids = list(df['study_id'].unique())"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.115104Z",
     "start_time": "2024-10-01T20:42:52.038167Z"
    }
   },
   "execution_count": 652,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.158808Z",
     "start_time": "2024-10-01T20:42:52.111608Z"
    }
   },
   "execution_count": 653,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# LABELS = list(sample_sub.columns[1:])\n",
    "# LABELS"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.219596Z",
     "start_time": "2024-10-01T20:42:52.154805Z"
    }
   },
   "execution_count": 654,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# CONDITIONS = [\n",
    "#     'spinal_canal_stenosis', \n",
    "#     'left_neural_foraminal_narrowing', \n",
    "#     'right_neural_foraminal_narrowing',\n",
    "#     'left_subarticular_stenosis',\n",
    "#     'right_subarticular_stenosis'\n",
    "# ]\n",
    "\n",
    "# LEVELS = [\n",
    "#     'l1_l2',\n",
    "#     'l2_l3',\n",
    "#     'l3_l4',\n",
    "#     'l4_l5',\n",
    "#     'l5_s1',\n",
    "# ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.260381Z",
     "start_time": "2024-10-01T20:42:52.216Z"
    }
   },
   "execution_count": 655,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.328284Z",
     "start_time": "2024-10-01T20:42:52.248958Z"
    }
   },
   "execution_count": 656,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24TestDataset(Dataset):\n",
    "#     def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "#         self.df = df\n",
    "#         self.study_ids = study_ids\n",
    "#         self.transform = transform\n",
    "#         self.phase = phase\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.study_ids)\n",
    "    \n",
    "#     def get_img_paths(self, study_id, series_desc):\n",
    "#         pdf = self.df[self.df['study_id']==study_id]\n",
    "#         pdf_ = pdf[pdf['series_description']==series_desc]\n",
    "#         allimgs = []\n",
    "#         for i, row in pdf_.iterrows():\n",
    "#             pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n",
    "#             pimgs = sorted(pimgs, key=natural_keys)\n",
    "#             allimgs.extend(pimgs)\n",
    "            \n",
    "#         return allimgs\n",
    "    \n",
    "#     def read_dcm_ret_arr(self, src_path):\n",
    "#         dicom_data = pydicom.dcmread(src_path)\n",
    "#         image = dicom_data.pixel_array\n",
    "#         image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "#         img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n",
    "#         assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n",
    "#         return img\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n",
    "#         st_id = self.study_ids[idx]        \n",
    "        \n",
    "#         # Sagittal T1\n",
    "#         allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n",
    "#         if len(allimgs_st1)==0:\n",
    "#             print(st_id, ': Sagittal T1, has no images')\n",
    "        \n",
    "#         else:\n",
    "#             step = len(allimgs_st1) / 10.0\n",
    "#             st = len(allimgs_st1)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st1)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n",
    "#                     x[..., j] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T1')\n",
    "#                     pass\n",
    "            \n",
    "#         # Sagittal T2/STIR\n",
    "#         allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n",
    "#         if len(allimgs_st2)==0:\n",
    "#             print(st_id, ': Sagittal T2/STIR, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_st2) / 10.0\n",
    "#             st = len(allimgs_st2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st2)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n",
    "#                     x[..., j+10] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T2/STIR')\n",
    "#                     pass\n",
    "            \n",
    "#         # Axial T2\n",
    "#         allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n",
    "#         if len(allimgs_at2)==0:\n",
    "#             print(st_id, ': Axial T2, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_at2) / 10.0\n",
    "#             st = len(allimgs_at2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_at2)+0.0001\n",
    "\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n",
    "#                     x[..., j+20] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Axial T2')\n",
    "#                     pass  \n",
    "            \n",
    "            \n",
    "#         if self.transform is not None:\n",
    "#             x = self.transform(image=x)['image']\n",
    "\n",
    "#         x = x.transpose(2, 0, 1)\n",
    "                \n",
    "#         return x, str(st_id)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.358650Z",
     "start_time": "2024-10-01T20:42:52.318226Z"
    }
   },
   "execution_count": 657,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# transforms_test = A.Compose([\n",
    "#     A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "# ])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.439856Z",
     "start_time": "2024-10-01T20:42:52.354761Z"
    }
   },
   "execution_count": 658,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_ds = RSNA24TestDataset(df, study_ids, transform=transforms_test)\n",
    "# test_dl = DataLoader(\n",
    "#     test_ds, \n",
    "#     batch_size=1, \n",
    "#     shuffle=False,\n",
    "#     num_workers=N_WORKERS,\n",
    "#     pin_memory=True,\n",
    "#     drop_last=False\n",
    "# )"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.481399Z",
     "start_time": "2024-10-01T20:42:52.424646Z"
    }
   },
   "execution_count": 659,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24Model(nn.Module):\n",
    "#     def __init__(self, model_name, in_c=30, n_classes=75, pretrained=True, features_only=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(\n",
    "#                                     model_name,\n",
    "#                                     pretrained=pretrained, \n",
    "#                                     features_only=features_only,\n",
    "#                                     in_chans=in_c,\n",
    "#                                     num_classes=n_classes,\n",
    "#                                     global_pool='avg'\n",
    "#                                     )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         y = self.model(x)\n",
    "#         return y"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.557443Z",
     "start_time": "2024-10-01T20:42:52.470475Z"
    }
   },
   "execution_count": 660,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# models = []"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.600699Z",
     "start_time": "2024-10-01T20:42:52.542131Z"
    }
   },
   "execution_count": 661,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import glob\n",
    "# DENSE_CKPT_PATHS = glob.glob(f'{DENSE161_DIR}best_wll_model_fold-*.pt')\n",
    "# DENSE_CKPT_PATHS = sorted(DENSE_CKPT_PATHS)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.691650Z",
     "start_time": "2024-10-01T20:42:52.586652Z"
    }
   },
   "execution_count": 662,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for i, cp in enumerate(DENSE_CKPT_PATHS):\n",
    "#     print(f'loading {cp}...')\n",
    "#     model = RSNA24Model(DENSE_MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=False)\n",
    "#     model.load_state_dict(torch.load(cp))\n",
    "#     model.eval()\n",
    "#     model.half()\n",
    "#     model.to(device)\n",
    "#     models.append(model)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.748107Z",
     "start_time": "2024-10-01T20:42:52.673690Z"
    }
   },
   "execution_count": 663,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "# y_preds = []\n",
    "# row_names = []\n",
    "\n",
    "# with tqdm(test_dl, leave=True) as pbar:\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (x, si) in enumerate(pbar):\n",
    "#             x = x.to(device)\n",
    "#             pred_per_study = np.zeros((25, 3))\n",
    "            \n",
    "#             for cond in CONDITIONS:\n",
    "#                 for level in LEVELS:\n",
    "#                     row_names.append(si[0] + '_' + cond + '_' + level)\n",
    "            \n",
    "#             with autocast:\n",
    "#                 for m in models:\n",
    "#                     y = m(x)[0]\n",
    "#                     for col in range(N_LABELS):\n",
    "#                         pred = y[col*3:col*3+3]\n",
    "#                         y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "#                         pred_per_study[col] += y_pred / len(models)\n",
    "#                 y_preds.append(pred_per_study)\n",
    "\n",
    "# y_preds = np.concatenate(y_preds, axis=0)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.835772Z",
     "start_time": "2024-10-01T20:42:52.729292Z"
    }
   },
   "execution_count": 664,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make Submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# sub = pd.DataFrame()\n",
    "# sub['row_id'] = row_names\n",
    "# sub[LABELS] = y_preds\n",
    "# sub.head(25)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.866474Z",
     "start_time": "2024-10-01T20:42:52.831652Z"
    }
   },
   "execution_count": 665,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sub.to_csv('submission_4.csv', index=False)\n",
    "# pd.read_csv('submission_4.csv').head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.939464Z",
     "start_time": "2024-10-01T20:42:52.862922Z"
    }
   },
   "execution_count": 666,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "We created the dataset, performed training, and inference in this notebook. \n",
    "\n",
    "This competition is a bit complicated to handle the dataset, so there may be a better way.\n",
    "\n",
    "I think there are many other areas to improve in my notebook. I hope you can learn from my notebook and get a better score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [RSNA Lumbar Spine Prediction](https://www.kaggle.com/code/marwanashref/rsna-lumbar-spine-prediction) \n",
    "### [Marwan Ashref](https://www.kaggle.com/marwanashref)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import the Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from collections import OrderedDict\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import AdamW\n",
    "# import timm\n",
    "# from timm.utils import ModelEmaV2\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "# import albumentations as A\n",
    "# from sklearn.model_selection import KFold\n",
    "# import re\n",
    "# import pydicom"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:52.981212Z",
     "start_time": "2024-10-01T20:42:52.935985Z"
    }
   },
   "execution_count": 667,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# import math, random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.054789Z",
     "start_time": "2024-10-01T20:42:52.969934Z"
    }
   },
   "execution_count": 668,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load & Edit The Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "# OUTPUT_DIR = f'/kaggle/input/rsna2024-lsdc-training-baseline/rsna24-results'\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.092205Z",
     "start_time": "2024-10-01T20:42:53.039574Z"
    }
   },
   "execution_count": 669,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # Configuration\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 8620\n",
    "# IMG_SIZE = (512, 512)\n",
    "# IN_CHANS = 42\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "# N_FOLDS = 5\n",
    "# MODEL_NAME = \"edgenext_base.in21k_ft_in1k\"\n",
    "# BATCH_SIZE = 1\n",
    "# data_dir = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.178614Z",
     "start_time": "2024-10-01T20:42:53.088285Z"
    }
   },
   "execution_count": 670,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # Device setup\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Load DataFrames\n",
    "# df = pd.read_csv(f'{data_dir}/test_series_descriptions.csv')\n",
    "# study_ids = df['study_id'].unique().tolist()\n",
    "\n",
    "# sample_sub = pd.read_csv(f'{data_dir}/sample_submission.csv')\n",
    "# LABELS = sample_sub.columns[1:].tolist()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.230625Z",
     "start_time": "2024-10-01T20:42:53.160667Z"
    }
   },
   "execution_count": 671,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # Conditions and Levels\n",
    "# CONDITIONS = [\n",
    "#     'spinal_canal_stenosis', \n",
    "#     'left_neural_foraminal_narrowing', \n",
    "#     'right_neural_foraminal_narrowing',\n",
    "#     'left_subarticular_stenosis',\n",
    "#     'right_subarticular_stenosis'\n",
    "# ]\n",
    "\n",
    "# LEVELS = [\n",
    "#     'l1_l2',\n",
    "#     'l2_l3',\n",
    "#     'l3_l4',\n",
    "#     'l4_l5',\n",
    "#     'l5_s1',\n",
    "# ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.291771Z",
     "start_time": "2024-10-01T20:42:53.219664Z"
    }
   },
   "execution_count": 672,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # Helper functions\n",
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [atoi(c) for c in re.split(r'(\\d+)', text)]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.333051Z",
     "start_time": "2024-10-01T20:42:53.276785Z"
    }
   },
   "execution_count": 673,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# import glob\n",
    "# import cv2\n",
    "# import pydicom\n",
    "# import numpy as np\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import albumentations as A\n",
    "\n",
    "# class RSNA24TestDataset(Dataset):\n",
    "#     def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "#         self.df = df\n",
    "#         self.study_ids = study_ids\n",
    "#         self.transform = transform\n",
    "#         self.phase = phase\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.study_ids)\n",
    "\n",
    "#     def get_img_paths(self, study_id, series_desc):\n",
    "#         series_df = self.df[(self.df['study_id'] == study_id) & \n",
    "#                             (self.df['series_description'] == series_desc)]\n",
    "#         img_paths = []\n",
    "#         for _, row in series_df.iterrows():\n",
    "#             paths = sorted(glob.glob(f'{data_dir}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm'), \n",
    "#                            key=natural_keys)\n",
    "#             img_paths.extend(paths)\n",
    "#         return img_paths\n",
    "\n",
    "#     def read_dcm_image(self, src_path):\n",
    "#         dicom_data = pydicom.dcmread(src_path)\n",
    "#         image = dicom_data.pixel_array\n",
    "#         norm_img = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "#         resized_img = cv2.resize(norm_img, IMG_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "#         return resized_img.astype(np.uint8)\n",
    "\n",
    "#     def load_series_images(self, study_id, series_desc, start_idx):\n",
    "#         images = np.zeros((IMG_SIZE[0], IMG_SIZE[1], 14), dtype=np.uint8)\n",
    "#         img_paths = self.get_img_paths(study_id, series_desc)\n",
    "        \n",
    "#         if not img_paths:\n",
    "#             print(f'{study_id}: {series_desc} has no images')\n",
    "#             return images\n",
    "        \n",
    "#         step = len(img_paths) / 14.0\n",
    "#         mid_point = len(img_paths) / 2.0 - 6.0 * step\n",
    "        \n",
    "#         for j, i in enumerate(np.arange(mid_point, len(img_paths), step)):\n",
    "#             try:\n",
    "#                 idx = max(0, int(round(i - 0.5)))\n",
    "#                 images[..., j] = self.read_dcm_image(img_paths[idx])\n",
    "#             except Exception as e:\n",
    "#                 print(f'Failed to load {series_desc} for {study_id}: {e}')\n",
    "                \n",
    "#         return images\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         study_id = self.study_ids[idx]\n",
    "#         channels = 42\n",
    "#         x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], channels), dtype=np.uint8)\n",
    "\n",
    "#         # Load images for each series\n",
    "#         x[..., :14] = self.load_series_images(study_id, 'Sagittal T1', 0)\n",
    "#         x[..., 14:28] = self.load_series_images(study_id, 'Sagittal T2/STIR', 14)\n",
    "#         x[..., 28:] = self.load_series_images(study_id, 'Axial T2', 28)\n",
    "\n",
    "#         # Apply transformations\n",
    "#         if self.transform:\n",
    "#             x = self.transform(image=x)['image']\n",
    "\n",
    "#         x = x.transpose(2, 0, 1)  # Channels-first for PyTorch\n",
    "#         return x, str(study_id)\n",
    "\n",
    "# # Transformations\n",
    "# transforms_test = A.Compose([\n",
    "#     A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "# ])\n",
    "\n",
    "# # Dataset and DataLoader\n",
    "# test_ds = RSNA24TestDataset(df, study_ids, transform=transforms_test)\n",
    "# test_dl = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=N_WORKERS,\n",
    "#                      pin_memory=True, drop_last=False)\n"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.407615Z",
     "start_time": "2024-10-01T20:42:53.322351Z"
    }
   },
   "execution_count": 674,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import torch.nn as nn\n",
    "# import timm\n",
    "\n",
    "# class RSNA24Model(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Custom model class for RSNA 2024 Lumbar Spine Degenerative Classification.\n",
    "    \n",
    "#     Args:\n",
    "#         model_name (str): Name of the model architecture from the TIMM library.\n",
    "#         in_c (int): Number of input channels. Default is 42.\n",
    "#         n_classes (int): Number of output classes. Default is 75.\n",
    "#         pretrained (bool): If True, use pre-trained weights. Default is True.\n",
    "#         features_only (bool): If True, return features only instead of final output. Default is False.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, model_name, in_c=42, n_classes=75, pretrained=True, features_only=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(\n",
    "#             model_name,\n",
    "#             pretrained=pretrained,\n",
    "#             features_only=features_only,\n",
    "#             in_chans=in_c,\n",
    "#             num_classes=n_classes,\n",
    "#             global_pool='avg'\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Forward pass for the model.\n",
    "        \n",
    "#         Args:\n",
    "#             x (torch.Tensor): Input tensor with shape (batch_size, in_c, height, width).\n",
    "            \n",
    "#         Returns:\n",
    "#             torch.Tensor: Model output with shape (batch_size, n_classes).\n",
    "#         \"\"\"\n",
    "#         return self.model(x)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.459920Z",
     "start_time": "2024-10-01T20:42:53.404464Z"
    }
   },
   "execution_count": 675,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# df.head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.536800Z",
     "start_time": "2024-10-01T20:42:53.441819Z"
    }
   },
   "execution_count": 676,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Constants\n",
    "# CKPT_PATHS = sorted([\n",
    "#     \"/kaggle/input/rsna-2024-edgenext-base/model_fold-0.pt\",\n",
    "#     \"/kaggle/input/rsna-2024-edgenext-base/model_fold-1.pt\",\n",
    "#     \"/kaggle/input/rsna-2024-edgenext-base/model_fold-2.pt\",\n",
    "# ])\n",
    "\n",
    "# # Load Models\n",
    "# models = []\n",
    "# for cp in CKPT_PATHS:\n",
    "#     print(f'Loading checkpoint: {cp}...')\n",
    "#     model = RSNA24Model(MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=False)\n",
    "#     try:\n",
    "#         model.load_state_dict(torch.load(cp))\n",
    "#     except Exception as e:\n",
    "#         print(f'Error loading {cp}: {e}')\n",
    "#         continue\n",
    "\n",
    "#     model.eval()\n",
    "#     model.half()\n",
    "#     model.to(device)\n",
    "#     models.append(model)\n",
    "\n",
    "# # Autocast for mixed precision\n",
    "# autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "\n",
    "# # Predictions and Submission\n",
    "# y_preds = []\n",
    "# row_names = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for x, study_id in tqdm(test_dl, leave=True):\n",
    "#         x = x.to(device)\n",
    "#         pred_per_study = np.zeros((N_LABELS, 3))\n",
    "\n",
    "#         # Generate row names for submission\n",
    "#         for cond in CONDITIONS:\n",
    "#             for level in LEVELS:\n",
    "#                 row_names.append(f'{study_id[0]}_{cond}_{level}')\n",
    "\n",
    "#         with autocast:\n",
    "#             for model in models:\n",
    "#                 y = model(x)[0]\n",
    "#                 for col in range(N_LABELS):\n",
    "#                     pred = y[col * 3 : (col + 1) * 3]\n",
    "#                     y_pred = pred.float().softmax(dim=0).cpu().numpy()\n",
    "#                     pred_per_study[col] += y_pred / len(models)\n",
    "        \n",
    "#         y_preds.append(pred_per_study)\n",
    "\n",
    "# # Combine and save predictions\n",
    "# y_preds = np.concatenate(y_preds, axis=0)\n",
    "\n",
    "# submission_df = pd.DataFrame({\n",
    "#     'row_id': row_names,\n",
    "#     **{label: y_preds[:, i] for i, label in enumerate(LABELS)}\n",
    "# })\n",
    "\n",
    "# submission_df.to_csv('submission_5.csv', index=False)\n",
    "\n",
    "# # Verify Submission\n",
    "# print(pd.read_csv('submission_5.csv').head(3))\n"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.566800Z",
     "start_time": "2024-10-01T20:42:53.525444Z"
    }
   },
   "execution_count": 677,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Japan [RSNA[INF]edgenext_base_x512[LB.57]](https://www.kaggle.com/code/hideyukizushi/rsna-inf-edgenext-base-x512-lb-57)\n",
    "### [yukiZ](https://www.kaggle.com/hideyukizushi)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ℹ️ **Info**\n",
    "* **[2024/8/23]forked original great work kernels**\n",
    "    * https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline\n",
    "    * https://www.kaggle.com/code/wanyanwendi/rsna2024\n",
    "* **[2024/8/23]add my dataset**\n",
    "    * https://www.kaggle.com/datasets/hideyukizushi/rsna-2024-edgenext-base"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# import math, random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "# from collections import OrderedDict\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import AdamW\n",
    "# import timm\n",
    "# from timm.utils import ModelEmaV2\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "# import albumentations as A\n",
    "# from sklearn.model_selection import KFold\n",
    "# import re\n",
    "# import pydicom"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.650566Z",
     "start_time": "2024-10-01T20:42:53.563432Z"
    }
   },
   "execution_count": 678,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "# OUTPUT_DIR = f'/kaggle/input/rsna2024-lsdc-training-baseline/rsna24-results'\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 8620\n",
    "\n",
    "# IMG_SIZE = [512, 512]\n",
    "# IN_CHANS = 42\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "# N_FOLDS = 5\n",
    "\n",
    "# MODEL_NAME = \"edgenext_base.in21k_ft_in1k\"\n",
    "\n",
    "# BATCH_SIZE = 1\n",
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "# device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device\n",
    "# df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "# df.head()\n",
    "# study_ids = list(df['study_id'].unique())\n",
    "# sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')\n",
    "# LABELS = list(sample_sub.columns[1:])\n",
    "# LABELS\n",
    "# CONDITIONS = [\n",
    "#     'spinal_canal_stenosis', \n",
    "#     'left_neural_foraminal_narrowing', \n",
    "#     'right_neural_foraminal_narrowing',\n",
    "#     'left_subarticular_stenosis',\n",
    "#     'right_subarticular_stenosis'\n",
    "# ]\n",
    "\n",
    "# LEVELS = [\n",
    "#     'l1_l2',\n",
    "#     'l2_l3',\n",
    "#     'l3_l4',\n",
    "#     'l4_l5',\n",
    "#     'l5_s1',\n",
    "# ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.698325Z",
     "start_time": "2024-10-01T20:42:53.636106Z"
    }
   },
   "execution_count": 679,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.766418Z",
     "start_time": "2024-10-01T20:42:53.683557Z"
    }
   },
   "execution_count": 680,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24TestDataset(Dataset):\n",
    "#     def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "#         self.df = df\n",
    "#         self.study_ids = study_ids\n",
    "#         self.transform = transform\n",
    "#         self.phase = phase\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.study_ids)\n",
    "    \n",
    "#     def get_img_paths(self, study_id, series_desc):\n",
    "#         pdf = self.df[self.df['study_id']==study_id]\n",
    "#         pdf_ = pdf[pdf['series_description']==series_desc]\n",
    "#         allimgs = []\n",
    "#         for i, row in pdf_.iterrows():\n",
    "#             pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n",
    "#             pimgs = sorted(pimgs, key=natural_keys)\n",
    "#             allimgs.extend(pimgs)\n",
    "            \n",
    "#         return allimgs\n",
    "    \n",
    "#     def read_dcm_ret_arr(self, src_path):\n",
    "#         dicom_data = pydicom.dcmread(src_path)\n",
    "#         image = dicom_data.pixel_array\n",
    "#         image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "#         img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n",
    "#         assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n",
    "#         return img\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n",
    "#         st_id = self.study_ids[idx]        \n",
    "        \n",
    "#         # Sagittal T1\n",
    "#         allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n",
    "#         if len(allimgs_st1)==0:\n",
    "#             print(st_id, ': Sagittal T1, has no images')\n",
    "        \n",
    "#         else:\n",
    "#             step = len(allimgs_st1) / 14.0\n",
    "#             st = len(allimgs_st1)/2.0 - 6.0*step\n",
    "#             end = len(allimgs_st1)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n",
    "#                     x[..., j] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T1')\n",
    "#                     pass\n",
    "            \n",
    "#         # Sagittal T2/STIR\n",
    "#         allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n",
    "#         if len(allimgs_st2)==0:\n",
    "#             print(st_id, ': Sagittal T2/STIR, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_st2) / 14.0\n",
    "#             st = len(allimgs_st2)/2.0 - 6.0*step\n",
    "#             end = len(allimgs_st2)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n",
    "#                     x[..., j+14] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T2/STIR')\n",
    "#                     pass\n",
    "            \n",
    "#         # Axial T2\n",
    "#         allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n",
    "#         if len(allimgs_at2)==0:\n",
    "#             print(st_id, ': Axial T2, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_at2) / 14.0\n",
    "#             st = len(allimgs_at2)/2.0 - 6.0*step\n",
    "#             end = len(allimgs_at2)+0.0001\n",
    "\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n",
    "#                     x[..., j+28] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Axial T2')\n",
    "#                     pass  \n",
    "            \n",
    "            \n",
    "#         if self.transform is not None:\n",
    "#             x = self.transform(image=x)['image']\n",
    "\n",
    "#         x = x.transpose(2, 0, 1)\n",
    "                \n",
    "#         return x, str(st_id)\n",
    "# transforms_test = A.Compose([\n",
    "#     A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "# ])\n",
    "# test_ds = RSNA24TestDataset(df, study_ids, transform=transforms_test)\n",
    "# test_dl = DataLoader(\n",
    "#     test_ds, \n",
    "#     batch_size=1, \n",
    "#     shuffle=False,\n",
    "#     num_workers=N_WORKERS,\n",
    "#     pin_memory=True,\n",
    "#     drop_last=False\n",
    "# )"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.804087Z",
     "start_time": "2024-10-01T20:42:53.763842Z"
    }
   },
   "execution_count": 681,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24Model(nn.Module):\n",
    "#     def __init__(self, model_name, in_c=42, n_classes=75, pretrained=True, features_only=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(\n",
    "#                                     model_name,\n",
    "#                                     pretrained=pretrained, \n",
    "#                                     features_only=features_only,\n",
    "#                                     in_chans=in_c,\n",
    "#                                     num_classes=n_classes,\n",
    "#                                     global_pool='avg'\n",
    "#                                     )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         y = self.model(x)\n",
    "#         return y"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.865244Z",
     "start_time": "2024-10-01T20:42:53.792317Z"
    }
   },
   "execution_count": 682,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# models = []\n",
    "# import glob\n",
    "\n",
    "# CKPT_PATHS = [\n",
    "#     \"/kaggle/input/rsna-2024-edgenext-base/model_fold-0.pt\",\n",
    "#     \"/kaggle/input/rsna-2024-edgenext-base/model_fold-1.pt\",\n",
    "#     \"/kaggle/input/rsna-2024-edgenext-base/model_fold-2.pt\",\n",
    "# ]\n",
    "\n",
    "# CKPT_PATHS = sorted(CKPT_PATHS)\n",
    "# for i, cp in enumerate(CKPT_PATHS):\n",
    "#     print(f'loading {cp}...')\n",
    "#     model = RSNA24Model(MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=False)\n",
    "#     model.load_state_dict(torch.load(cp))\n",
    "#     model.eval()\n",
    "#     model.half()\n",
    "#     model.to(device)\n",
    "#     models.append(model)\n",
    "# autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "# y_preds = []\n",
    "# row_names = []\n",
    "\n",
    "# with tqdm(test_dl, leave=True) as pbar:\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (x, si) in enumerate(pbar):\n",
    "#             x = x.to(device)\n",
    "#             pred_per_study = np.zeros((25, 3))\n",
    "            \n",
    "#             for cond in CONDITIONS:\n",
    "#                 for level in LEVELS:\n",
    "#                     row_names.append(si[0] + '_' + cond + '_' + level)\n",
    "            \n",
    "#             with autocast:\n",
    "#                 for m in models:\n",
    "#                     y = m(x)[0]\n",
    "#                     for col in range(N_LABELS):\n",
    "#                         pred = y[col*3:col*3+3]\n",
    "#                         y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "#                         pred_per_study[col] += y_pred / len(models)\n",
    "#                 y_preds.append(pred_per_study)\n",
    "\n",
    "# y_preds = np.concatenate(y_preds, axis=0)\n",
    "# sub = pd.DataFrame()\n",
    "# sub['row_id'] = row_names\n",
    "# sub[LABELS] = y_preds\n",
    "# sub.head(25)\n",
    "# sub.to_csv('submission_6.csv', index=False)\n",
    "# pd.read_csv('submission_6.csv').head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "jupyter": {
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:53.906820Z",
     "start_time": "2024-10-01T20:42:53.861875Z"
    }
   },
   "execution_count": 683,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Germany [LSDC Yolo Approach](https://www.kaggle.com/code/namgalielei/lsdc-yolo-approach)\n",
    "### [Liam Nguyen](https://www.kaggle.com/namgalielei)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q --no-index --find-links /kaggle/input/ultralytics ultralytics"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.361614Z",
     "start_time": "2024-10-01T20:42:53.895337Z"
    }
   },
   "execution_count": 684,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm.auto import tqdm"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.366551Z",
     "start_time": "2024-10-01T20:42:54.330792Z"
    }
   },
   "execution_count": 685,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.380107Z",
     "start_time": "2024-10-01T20:42:54.332574Z"
    }
   },
   "execution_count": 685,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.387894Z",
     "start_time": "2024-10-01T20:42:54.334681Z"
    }
   },
   "execution_count": 685,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "EVAL = False # Change to True to compute the validation score\n",
    "IMG_DIR = '/images'\n",
    "FOLD = 0\n",
    "SAMPLE = False # True for quick debugging\n",
    "SEVERITIES = ['Normal/Mild', 'Moderate', 'Severe']\n",
    "LEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "\n",
    "SCS_WEIGHTS = ['/kaggle/input/lsdc-train-yolo-scs/lsdc_yolov8/train/weights/best.pt']\n",
    "\n",
    "SS_WEIGHTS = ['/kaggle/input/lsdc-train-yolo-ss/lsdc_yolov8/train/weights/best.pt',\n",
    "             '/kaggle/input/lsdc-yolo-ssv3/best.pt']\n",
    "\n",
    "NFN_WEIGHTS = ['/kaggle/input/lsdc-train-yolo-nfn/lsdc_yolov8/train/weights/best.pt',\n",
    "              '/kaggle/input/lsdc-yolo-nfnv3/best.pt']"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.401725Z",
     "start_time": "2024-10-01T20:42:54.336685Z"
    }
   },
   "execution_count": 686,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if EVAL:\n",
    "    import sys\n",
    "    sys.path.append('/kaggle/input/lsdc-utils')\n",
    "    from metrics import score as lsdc_scoring"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.407411Z",
     "start_time": "2024-10-01T20:42:54.338483Z"
    }
   },
   "execution_count": 687,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#DATA_DIR = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/\"\n",
    "DATA_DIR = \"data/\"\n",
    "\n",
    "train_val_df = pd.read_csv(DATA_DIR + 'train.csv')"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.412619Z",
     "start_time": "2024-10-01T20:42:54.340685Z"
    }
   },
   "execution_count": 688,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if EVAL:\n",
    "    train_xy = pd.read_csv(DATA_DIR + 'train_label_coordinates.csv')\n",
    "    des = pd.read_csv(DATA_DIR + 'train_series_descriptions.csv')\n",
    "else:    \n",
    "    des = pd.read_csv(DATA_DIR + 'test_series_descriptions.csv')"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.427245Z",
     "start_time": "2024-10-01T20:42:54.347634Z"
    }
   },
   "execution_count": 689,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.432554Z",
     "start_time": "2024-10-01T20:42:54.349774Z"
    }
   },
   "execution_count": 689,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def read_dcm(src_path):\n",
    "    dicom_data = pydicom.dcmread(src_path)\n",
    "    image = dicom_data.pixel_array\n",
    "    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n",
    "    return image\n",
    "\n",
    "def convert_dcm_to_jpg(file_path):\n",
    "    try:\n",
    "        # Read the DICOM file\n",
    "        image_array = read_dcm(file_path)\n",
    "        \n",
    "        # Define the output path\n",
    "        relative_path = os.path.relpath(file_path, start=input_directory)\n",
    "        output_path = os.path.join(output_directory, relative_path)\n",
    "        output_path = output_path.replace('.dcm', '.jpg')\n",
    "                \n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Save the image as a JPEG file\n",
    "        cv2.imwrite(output_path, image_array)\n",
    "        \n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_files(dcm_files):\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        # Wrap pool.map with tqdm to show the progress bar\n",
    "        list(tqdm(pool.imap(convert_dcm_to_jpg, dcm_files), total=len(dcm_files)))\n",
    "\n",
    "def get_dcm_files(directory):\n",
    "    dcm_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                dcm_files.append(os.path.join(root, file))\n",
    "    return dcm_files    "
   ],
   "metadata": {
    "_kg_hide-input": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:42:54.471645Z",
     "start_time": "2024-10-01T20:42:54.353904Z"
    }
   },
   "execution_count": 690,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Replace these with your input and output directories\n",
    "if not EVAL:\n",
    "    input_directory = DATA_DIR + 'test_images'\n",
    "\n",
    "    output_directory = IMG_DIR\n",
    "\n",
    "    # Get all .dcm files in the input directory\n",
    "    dcm_files = get_dcm_files(input_directory)\n",
    "\n",
    "    # Process the files using multiprocessing\n",
    "    process_files(dcm_files)\n",
    "\n",
    "    print(f\"Conversion completed. Images saved to {output_directory}\")\n",
    "else:\n",
    "    if not os.path.exists(IMG_DIR):\n",
    "        print('Unziping data..')\n",
    "        !unzip -q -d / /kaggle/input/lsdc-get-all-images/images.zip\n",
    "        print('Done unziping data')"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-10-01T20:42:54.356078Z"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-5:\n",
      "Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-9:\n",
      "Process SpawnPoolWorker-10:\n",
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-12:\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-13:\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/97 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dbe7aae698e46a1af3be11ad9fc0229"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-39:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-42:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-43:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-44:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-45:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-46:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-47:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-49:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-50:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-51:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-52:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-53:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-54:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-55:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-56:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-57:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-58:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-59:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-60:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-61:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-62:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-65:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-66:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-67:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-68:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-69:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-70:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-71:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-72:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-73:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-74:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-75:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-76:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-77:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-78:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-79:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-80:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-81:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-82:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-83:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-84:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-85:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-86:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-87:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-88:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-89:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-90:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-91:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-92:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-93:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-94:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-95:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-96:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-97:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/exide/rsna-lsdc/.lsdc/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'convert_dcm_to_jpg' on <module '__main__' (built-in)>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if EVAL:\n",
    "    fold_df = pd.read_csv('/kaggle/input/lsdc-fold-split/5folds.csv')\n",
    "    test_df = fold_df[fold_df.fold == FOLD]\n",
    "    \n",
    "else:\n",
    "    test_df = os.listdir(DATA_DIR + 'test_images')\n",
    "    test_df = pd.DataFrame(test_df, columns=['study_id'])\n",
    "    test_df['study_id'] = test_df['study_id'].astype(int)\n",
    "    \n",
    "test_df = test_df.merge(des, on=['study_id'])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def gen_label_map(CONDITIONS):\n",
    "    label2id = {}\n",
    "    id2label = {}\n",
    "    i = 0\n",
    "    for cond in CONDITIONS:\n",
    "        for level in LEVELS:\n",
    "            for severity in SEVERITIES:\n",
    "                cls_ = f\"{cond.lower().replace(' ', '_')}_{level}_{severity.lower()}\"\n",
    "                label2id[cls_] = i\n",
    "                id2label[i] = cls_\n",
    "                i+=1\n",
    "    return label2id, id2label\n",
    "                \n",
    "scs_label2id, scs_id2label = gen_label_map(['Spinal Canal Stenosis'])\n",
    "ss_label2id, ss_id2label = gen_label_map(['Left Subarticular Stenosis', 'Right Subarticular Stenosis'])\n",
    "nfn_label2id, nfn_id2label = gen_label_map(['Left Neural Foraminal Narrowing', 'Right Neural Foraminal Narrowing'])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO Model\n",
    "scs_models = []\n",
    "for weight in SCS_WEIGHTS:\n",
    "    scs_models.append(YOLO(weight))\n",
    "    \n",
    "ss_models = []\n",
    "for weight in SS_WEIGHTS:\n",
    "    ss_models.append(YOLO(weight))\n",
    "    \n",
    "nfn_models = []\n",
    "for weight in NFN_WEIGHTS:\n",
    "    nfn_models.append(YOLO(weight))"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_label_set = train_val_df.iloc[0, 1:].index.tolist()\n",
    "scs_label_set = all_label_set[:5]\n",
    "nfn_label_set = all_label_set[5:15]\n",
    "ss_label_set = all_label_set[15:]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "settings = [\n",
    "    ( 'Sagittal T2/STIR', scs_models, scs_id2label, scs_label_set, 0.01),\n",
    "    ( 'Axial T2', ss_models, ss_id2label, ss_label_set, 0.01),\n",
    "    ( 'Sagittal T1', nfn_models, nfn_id2label, nfn_label_set, 0.1)\n",
    "]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import defaultdict"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pred_rows = []\n",
    "\n",
    "for modality, models, id2label, label_set, thresh in settings:\n",
    "    mod_df = test_df[test_df.series_description == modality]\n",
    "    \n",
    "    if SAMPLE:\n",
    "        mod_df = mod_df.sample(20, random_state=610)\n",
    "    \n",
    "    # for each study, at each level and condition, get the maximum probability score\n",
    "    for study_id, group in tqdm(mod_df.groupby('study_id')):\n",
    "        predictions = defaultdict(list)\n",
    "        for i, row in group.iterrows():\n",
    "            # predict on all images from all the series\n",
    "            series_dir = os.path.join(IMG_DIR, str(row['study_id']), str(row['series_id']))\n",
    "            for model in models:\n",
    "                results = model(series_dir, conf=thresh, verbose=False)\n",
    "                for res in results:\n",
    "                    for pred_class, conf in zip(res.boxes.cls, res.boxes.conf):\n",
    "                        pred_class = pred_class.item()\n",
    "                        conf = conf.item()\n",
    "                        _class = id2label[pred_class]\n",
    "                        predictions[_class].append(conf)\n",
    "        \n",
    "        # aggregate the result on images to obtain study-level prediction\n",
    "        for condition in label_set:\n",
    "            res_dict = {'row_id': f'{study_id}_{condition}' }\n",
    "\n",
    "            score_vec = []\n",
    "            for severity in SEVERITIES:\n",
    "                severity = severity.lower()\n",
    "                key = f'{condition}_{severity}'\n",
    "                if len(predictions[key]) > 0:\n",
    "                    score = np.max(predictions[key])\n",
    "                else:\n",
    "                    score = thresh\n",
    "                score_vec.append(score)\n",
    "                \n",
    "            # normalize score to sum to 1\n",
    "            score_vec = torch.tensor(score_vec)\n",
    "            score_vec = score_vec / score_vec.sum()\n",
    "\n",
    "            for idx, severity in enumerate(SEVERITIES):\n",
    "                res_dict[severity.replace('/', '_').lower()] = score_vec[idx].item()\n",
    "\n",
    "            pred_rows.append(res_dict)\n"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pred_df = pd.DataFrame(pred_rows)\n",
    "pred_df"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pred_df.to_csv('submission_7.csv', index=False)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def sample_weight(row):\n",
    "    if row['normal_mild'] == 1:\n",
    "        return 1\n",
    "    if row['moderate'] == 1:\n",
    "        return 2\n",
    "    if row['severe'] == 1:\n",
    "        return 4\n",
    "    raise ValueError('No such value')\n",
    "    \n",
    "def get_class(row):\n",
    "    return np.argmax([row['normal_mild'], row['moderate'], row['severe']])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if EVAL:\n",
    "    gt_df = train_val_df.dropna().melt(id_vars=['study_id'], value_vars=all_label_set)\n",
    "    gt_df['row_id'] = gt_df['study_id'].astype(str) + '_' + gt_df['variable']\n",
    "    gt_df= gt_df[['row_id', 'value']]\n",
    "    gt_df = pd.get_dummies(gt_df, columns=['value'], dtype=int)\n",
    "    gt_df.columns = ['row_id', 'moderate', 'normal_mild', 'severe']\n",
    "    gt_df = gt_df[['row_id', 'normal_mild', 'moderate', 'severe']]\n",
    "    gt_df['sample_weight'] = gt_df.apply(sample_weight, axis=1)\n",
    "\n",
    "    gt_df1 = gt_df.merge(pred_df['row_id'], how='inner', on='row_id').sort_values('row_id').reset_index(drop=True)\n",
    "    pred_df1 = pred_df.merge(gt_df1['row_id'], how='inner', on='row_id').sort_values('row_id').reset_index(drop=True)\n",
    "    gt_df1['pred_cls'] = gt_df1.apply(get_class, axis=1)\n",
    "    pred_df1['pred_cls'] = pred_df1.apply(get_class, axis=1)\n",
    "\n",
    "    gt_df1[(gt_df1['pred_cls'] != pred_df1['pred_cls'])]\n",
    "    pred_df1[(gt_df1['pred_cls'] != pred_df1['pred_cls'])]\n",
    "    print('Label count:\\n', gt_df1['pred_cls'].value_counts(normalize=True))\n",
    "    print('Prediction accuracy:', (gt_df1['pred_cls'] == pred_df1['pred_cls']).mean())\n",
    "    print()\n",
    "\n",
    "    target_levels = ['normal_mild', 'moderate', 'severe']\n",
    "    loss = lsdc_scoring(gt_df1.drop(['pred_cls'], axis=1), pred_df1.drop(['pred_cls'], axis=1), row_id_column_name='row_id', any_severe_scalar=1)\n",
    "    print('Total weighted log loss:', loss)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ls"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Japan [LB0.55 | Inference by tempature0.9 | RSNA2024](https://www.kaggle.com/code/taikimori/lb0-55-inference-by-tempature0-9-rsna2024)\n",
    "### [Taimo](https://www.kaggle.com/taikimori)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Setting\n",
    "\n",
    "* model: timm/efficientnet_b5.sw_in12k_ft_in1k\n",
    "* tempature: 0.9\n",
    "* training code: I borrowed [the notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-training-baseline) for training "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libralies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import sys\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# import math, random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "# import timm\n",
    "# from timm.utils import ModelEmaV2\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# import albumentations as A\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# import re\n",
    "# import pydicom"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# OUTPUT_DIR = f'/kaggle/input/rsna-2024-externals/cv_0.618_rsna24-results'\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# N_WORKERS = os.cpu_count()\n",
    "# USE_AMP = True\n",
    "# SEED = 8620\n",
    "\n",
    "# IMG_SIZE = [512, 512]\n",
    "# IN_CHANS = 30\n",
    "# N_LABELS = 25\n",
    "# N_CLASSES = 3 * N_LABELS\n",
    "\n",
    "# N_FOLDS = 5\n",
    "\n",
    "# MODEL_NAME = \"tf_efficientnet_b5.ns_jft_in1k\"\n",
    "\n",
    "# BATCH_SIZE = 1"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "# df.head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# study_ids = list(df['study_id'].unique())"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# LABELS = list(sample_sub.columns[1:])\n",
    "# LABELS"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# CONDITIONS = [\n",
    "#     'spinal_canal_stenosis', \n",
    "#     'left_neural_foraminal_narrowing', \n",
    "#     'right_neural_foraminal_narrowing',\n",
    "#     'left_subarticular_stenosis',\n",
    "#     'right_subarticular_stenosis'\n",
    "# ]\n",
    "\n",
    "# LEVELS = [\n",
    "#     'l1_l2',\n",
    "#     'l2_l3',\n",
    "#     'l3_l4',\n",
    "#     'l4_l5',\n",
    "#     'l5_s1',\n",
    "# ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24TestDataset(Dataset):\n",
    "#     def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "#         self.df = df\n",
    "#         self.study_ids = study_ids\n",
    "#         self.transform = transform\n",
    "#         self.phase = phase\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.study_ids)\n",
    "    \n",
    "#     def get_img_paths(self, study_id, series_desc):\n",
    "#         pdf = self.df[self.df['study_id']==study_id]\n",
    "#         pdf_ = pdf[pdf['series_description']==series_desc]\n",
    "#         allimgs = []\n",
    "#         for i, row in pdf_.iterrows():\n",
    "#             pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n",
    "#             pimgs = sorted(pimgs, key=natural_keys)\n",
    "#             allimgs.extend(pimgs)\n",
    "            \n",
    "#         return allimgs\n",
    "    \n",
    "#     def read_dcm_ret_arr(self, src_path):\n",
    "#         dicom_data = pydicom.dcmread(src_path)\n",
    "#         image = dicom_data.pixel_array\n",
    "#         image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "#         img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n",
    "#         assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n",
    "#         return img\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n",
    "#         st_id = self.study_ids[idx]        \n",
    "        \n",
    "#         # Sagittal T1\n",
    "#         allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n",
    "#         if len(allimgs_st1)==0:\n",
    "#             print(st_id, ': Sagittal T1, has no images')\n",
    "        \n",
    "#         else:\n",
    "#             step = len(allimgs_st1) / 10.0\n",
    "#             st = len(allimgs_st1)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st1)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n",
    "#                     x[..., j] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T1')\n",
    "#                     pass\n",
    "            \n",
    "#         # Sagittal T2/STIR\n",
    "#         allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n",
    "#         if len(allimgs_st2)==0:\n",
    "#             print(st_id, ': Sagittal T2/STIR, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_st2) / 10.0\n",
    "#             st = len(allimgs_st2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_st2)+0.0001\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n",
    "#                     x[..., j+10] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Sagittal T2/STIR')\n",
    "#                     pass\n",
    "            \n",
    "#         # Axial T2\n",
    "#         allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n",
    "#         if len(allimgs_at2)==0:\n",
    "#             print(st_id, ': Axial T2, has no images')\n",
    "            \n",
    "#         else:\n",
    "#             step = len(allimgs_at2) / 10.0\n",
    "#             st = len(allimgs_at2)/2.0 - 4.0*step\n",
    "#             end = len(allimgs_at2)+0.0001\n",
    "\n",
    "#             for j, i in enumerate(np.arange(st, end, step)):\n",
    "#                 try:\n",
    "#                     ind2 = max(0, int((i-0.5001).round()))\n",
    "#                     img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n",
    "#                     x[..., j+20] = img.astype(np.uint8)\n",
    "#                 except:\n",
    "#                     print(f'failed to load on {st_id}, Axial T2')\n",
    "#                     pass  \n",
    "            \n",
    "            \n",
    "#         if self.transform is not None:\n",
    "#             x = self.transform(image=x)['image']\n",
    "\n",
    "#         x = x.transpose(2, 0, 1)\n",
    "                \n",
    "#         return x, str(st_id)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# transforms_test = A.Compose([\n",
    "#     A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "# ])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_ds = RSNA24TestDataset(df, study_ids, transform=transforms_test)\n",
    "# test_dl = DataLoader(\n",
    "#     test_ds, \n",
    "#     batch_size=1, \n",
    "#     shuffle=False,\n",
    "#     num_workers=N_WORKERS,\n",
    "#     pin_memory=True,\n",
    "#     drop_last=False\n",
    "# )"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# class RSNA24Model(nn.Module):\n",
    "#     def __init__(self, model_name, in_c=30, n_classes=75, pretrained=True, features_only=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(\n",
    "#                                     model_name,\n",
    "#                                     pretrained=pretrained, \n",
    "#                                     features_only=features_only,\n",
    "#                                     in_chans=in_c,\n",
    "#                                     num_classes=n_classes,\n",
    "#                                     global_pool='avg'\n",
    "#                                     )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         y = self.model(x)\n",
    "#         return y"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# models = []"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import glob\n",
    "# CKPT_PATHS = glob.glob('/kaggle/input/rsna-2024-externals/cv_0.618_rsna24-results/best_wll_model_fold-*.pt')\n",
    "# CKPT_PATHS = sorted(CKPT_PATHS)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-09-12T15:19:59.356529Z",
     "iopub.execute_input": "2024-09-12T15:19:59.356902Z",
     "iopub.status.idle": "2024-09-12T15:19:59.361986Z",
     "shell.execute_reply.started": "2024-09-12T15:19:59.356858Z",
     "shell.execute_reply": "2024-09-12T15:19:59.361168Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for i, cp in enumerate(CKPT_PATHS):\n",
    "#     print(f'loading {cp}...')\n",
    "#     model = RSNA24Model(MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=False)\n",
    "#     model.load_state_dict(torch.load(cp))\n",
    "#     model.eval()\n",
    "#     model.half()\n",
    "#     model.to(device)\n",
    "#     models.append(model)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n",
    "# y_preds = []\n",
    "# row_names = []\n",
    "\n",
    "# with tqdm(test_dl, leave=True) as pbar:\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (x, si) in enumerate(pbar):\n",
    "#             x = x.to(device)\n",
    "#             pred_per_study = np.zeros((25, 3))\n",
    "            \n",
    "#             for cond in CONDITIONS:\n",
    "#                 for level in LEVELS:\n",
    "#                     row_names.append(si[0] + '_' + cond + '_' + level)\n",
    "            \n",
    "#             with autocast:\n",
    "#                 for m in models:\n",
    "#                     y = m(x)[0]\n",
    "#                     for col in range(N_LABELS):\n",
    "#                         pred = y[col*3:col*3+3]\n",
    "#                         y_pred = (pred.float()/0.9).softmax(0).cpu().numpy()\n",
    "#                         pred_per_study[col] += y_pred / len(models)\n",
    "#                 y_preds.append(pred_per_study)\n",
    "\n",
    "# y_preds = np.concatenate(y_preds, axis=0)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make Submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# sub = pd.DataFrame()\n",
    "# sub['row_id'] = row_names\n",
    "# sub[LABELS] = y_preds\n",
    "# sub.head(25)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sub.to_csv('submission_8.csv', index=False)\n",
    "# pd.read_csv('submission_8.csv').head()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## USA [3D Vision Transformer Single-Stage (Inference)](https://www.kaggle.com/code/vsahin/3d-vision-transformer-single-stage-inference)\n",
    "### [Victor S](https://www.kaggle.com/vsahin)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dependencies\n",
    "#### timm_3d\n",
    "Timm models adapted for 3D data\n",
    "#### torchio\n",
    "Medical imaging focused library. Used for 3D augmentations here\n",
    "#### spacecutter\n",
    "Ordinal regression layer and related loss and callback functions i.e. `LogisticCumulativeLink`\n",
    "#### open3d\n",
    "Used for point cloud initialization and transformation. At first I used this for voxelization too, but dropped it in favor of a simpler sampling approach due to slow runtime."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "%pip install --quiet /kaggle/input/timm_3d_deps/other/initial/9/pydicom/pydicom/pydicom-2.4.4-py3-none-any.whl\n",
    "%pip install timm_3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/timm_3d/\n",
    "%pip install torchio --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/torchio/\n",
    "%pip install itk --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/itk/itk\n",
    "%pip install skorch --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/skorch/skorch\n",
    "%pip install spacecutter --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/spacecutter/\n",
    "%pip install open3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/open3d"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = DATA_DIR + \"\""
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def retrieve_test_data(data_path):\n",
    "    test_df = pd.read_csv(data_path + 'test_series_descriptions.csv')\n",
    "\n",
    "    return test_df\n",
    "\n",
    "retrieve_test_data(data_path)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def retrieve_image_paths(base_path, study_id, series_id):\n",
    "    series_dir = os.path.join(base_path, str(study_id), str(series_id))\n",
    "    images = os.listdir(series_dir)\n",
    "    image_paths = [os.path.join(series_dir, img) for img in images]\n",
    "    return image_paths"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Loading\n",
    "\n",
    "Quite a few things are happening here. Refer here for more details on where the affine transforms come from: https://nipy.org/nibabel/dicom/dicom_orientation.html\n",
    "\n",
    "The rough idea is -- converting the slices into point cloud format, transforming them into the same patient coordinate space, then converting into a voxel grid.\n",
    "\n",
    "1. Resizing each slice -- doing this first reduces the runtime from having to transform each point just to resize/downsample later anyway.\n",
    "2. Duplicating the slices and applying the affine transforms -- I found duplicating each slice by slice thickness makes it easier for the model to learn. The spatial information between slices might get somewhat warped, but the relative ordering is still the same but with much less empty space.\n",
    "3. Sampling into a voxel grid -- I am simply scaling the coordinates into the desired grid size, then sampling each channel by max."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import open3d as o3d\n",
    "from pydicom import dcmread\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "def read_study_as_pcd(dir_path, series_types_dict=None, downsampling_factor=1, img_size=(256, 256)):\n",
    "    pcd_overall = o3d.geometry.PointCloud()\n",
    "\n",
    "    for path in glob.glob(os.path.join(dir_path, \"**/*.dcm\"), recursive=True):\n",
    "        dicom_slice = dcmread(path)\n",
    "\n",
    "        series_id = os.path.basename(os.path.dirname(path))\n",
    "        study_id = os.path.basename(os.path.dirname(os.path.dirname(path)))\n",
    "        if series_types_dict is None or int(series_id) not in series_types_dict:\n",
    "            series_desc = dicom_slice.SeriesDescription\n",
    "        else:\n",
    "            series_desc = series_types_dict[int(series_id)]\n",
    "            series_desc = series_desc.split(\" \")[-1]\n",
    "\n",
    "        x_orig, y_orig = dicom_slice.pixel_array.shape\n",
    "        img = np.expand_dims(cv2.resize(dicom_slice.pixel_array, img_size, interpolation=cv2.INTER_AREA), -1)\n",
    "        x, y, z = np.where(img)\n",
    "\n",
    "        downsampling_factor_iter = max(downsampling_factor, int(math.ceil(len(x) / 6e6)))\n",
    "\n",
    "        index_voxel = np.vstack((x, y, z))[:, ::downsampling_factor_iter]\n",
    "        grid_index_array = index_voxel.T\n",
    "        pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(grid_index_array.astype(np.float64)))\n",
    "\n",
    "        vals = np.expand_dims(img[x, y, z][::downsampling_factor_iter], -1)\n",
    "        if series_desc == \"T1\":\n",
    "            vals = np.pad(vals, ((0, 0), (0, 2)))\n",
    "        elif series_desc == \"T2\":\n",
    "            vals = np.pad(vals, ((0, 0), (1, 1)))\n",
    "        elif series_desc == \"T2/STIR\":\n",
    "            vals = np.pad(vals, ((0, 0), (2, 0)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown series desc: {series_desc}\")\n",
    "\n",
    "        pcd.colors = o3d.utility.Vector3dVector(vals.astype(np.float64))\n",
    "\n",
    "        dX, dY = dicom_slice.PixelSpacing\n",
    "        dZ = dicom_slice.SliceThickness\n",
    "\n",
    "        X = np.array(list(dicom_slice.ImageOrientationPatient[:3]) + [0]) * dX\n",
    "        Y = np.array(list(dicom_slice.ImageOrientationPatient[3:]) + [0]) * dY\n",
    "\n",
    "        for z in range(int(dZ)):\n",
    "            pos = list(dicom_slice.ImagePositionPatient)\n",
    "            if series_desc == \"T2\":\n",
    "                pos[-1] += z\n",
    "            else:\n",
    "                pos[0] += z\n",
    "            S = np.array(pos + [1])\n",
    "\n",
    "            transform_matrix = np.array([X, Y, np.zeros(len(X)), S]).T\n",
    "            transform_matrix = transform_matrix @ np.matrix(\n",
    "                [[0, y_orig / img_size[1], 0, 0],\n",
    "                 [x_orig / img_size[0], 0, 0, 0],\n",
    "                 [0, 0, 1, 0],\n",
    "                 [0, 0, 0, 1]]\n",
    "            )\n",
    "\n",
    "            pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n",
    "\n",
    "    return pcd_overall\n",
    "\n",
    "\n",
    "\n",
    "def read_study_as_voxel_grid(dir_path, series_type_dict=None, downsampling_factor=1, img_size=(256, 256)):\n",
    "    pcd_overall = read_study_as_pcd(dir_path,\n",
    "                                    series_types_dict=series_type_dict,\n",
    "                                    downsampling_factor=downsampling_factor,\n",
    "                                    img_size=img_size)\n",
    "    box = pcd_overall.get_axis_aligned_bounding_box()\n",
    "\n",
    "    max_b = np.array(box.get_max_bound())\n",
    "    min_b = np.array(box.get_min_bound())\n",
    "\n",
    "    pts = (np.array(pcd_overall.points) - (min_b)) * (\n",
    "                (img_size[0] - 1, img_size[0] - 1, img_size[0] - 1) / (max_b - min_b))\n",
    "    coords = np.round(pts).astype(np.int32)\n",
    "    vals = np.array(pcd_overall.colors, dtype=np.float16)\n",
    "\n",
    "    grid = np.zeros((3, img_size[0], img_size[0], img_size[0]), dtype=np.float16)\n",
    "    indices = coords[:, 0], coords[:, 1], coords[:, 2]\n",
    "\n",
    "    np.maximum.at(grid[0], indices, vals[:, 0])\n",
    "    np.maximum.at(grid[1], indices, vals[:, 1])\n",
    "    np.maximum.at(grid[2], indices, vals[:, 2])\n",
    "\n",
    "\n",
    "    return grid"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchio as tio\n",
    "import torch.nn as nn\n",
    "import pydicom\n",
    "\n",
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"Spinal Canal Stenosis\"],\n",
    "    \"Axial T2\": [\"Left Subarticular Stenosis\", \"Right Subarticular Stenosis\"],\n",
    "    \"Sagittal T1\": [\"Left Neural Foraminal Narrowing\", \"Right Neural Foraminal Narrowing\"],\n",
    "}\n",
    "\n",
    "\n",
    "class PatientLevelTestset(Dataset):\n",
    "    def __init__(self,\n",
    "                 base_path: str,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 transform_3d=None):\n",
    "        self.base_path = base_path\n",
    "\n",
    "        self.dataframe = (dataframe[['study_id', \"series_id\", \"series_description\"]]\n",
    "                          .drop_duplicates())\n",
    "\n",
    "        self.subjects = self.dataframe[['study_id']].drop_duplicates().reset_index(drop=True)\n",
    "        self.series_descs = {e[0]: e[1] for e in self.dataframe[[\"series_id\", \"series_description\"]].drop_duplicates().values}\n",
    "\n",
    "        self.transform_3d = transform_3d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        curr = self.subjects.iloc[index]\n",
    "        study_path = os.path.join(self.base_path, str(curr[\"study_id\"]))\n",
    "\n",
    "        study_images = read_study_as_voxel_grid(study_path, self.series_descs)\n",
    "\n",
    "        if self.transform_3d is not None:\n",
    "            study_images = self.transform_3d(torch.FloatTensor(study_images))  # .data\n",
    "            return study_images.to(torch.half), str(curr[\"study_id\"])\n",
    "\n",
    "        return torch.HalfTensor(study_images), str(curr[\"study_id\"])\n"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transform_3d = tio.Compose([\n",
    "    tio.RescaleIntensity([0, 1]),\n",
    "])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_subject_level_testset_and_loader(df: pd.DataFrame,\n",
    "                                             transform_3d,\n",
    "                                             base_path: str,\n",
    "                                             batch_size=1,\n",
    "                                             num_workers=0):\n",
    "    testset = PatientLevelTestset(base_path, df, transform_3d=transform_3d)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return testset, test_loader"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "data = retrieve_test_data(data_path)\n",
    "dataset, dataloader = create_subject_level_testset_and_loader(data, transform_3d, os.path.join(data_path, \"test_images\"))"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "import torch\n",
    "\n",
    "grid = dataset[0][0]\n",
    "\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "\n",
    "axs[0, 0].imshow(grid[0, 128])\n",
    "axs[1, 0].imshow(grid[1, 128])\n",
    "axs[2, 0].imshow(grid[2, 128])\n",
    "\n",
    "axs[0, 1].imshow(grid[0, :, 128])\n",
    "axs[1, 1].imshow(grid[1, :, 128])\n",
    "axs[2, 1].imshow(grid[2, :, 128])\n",
    "\n",
    "axs[0, 2].imshow(grid[0, :, :, 128])\n",
    "axs[1, 2].imshow(grid[1, :, :, 128])\n",
    "axs[2, 2].imshow(grid[2, :, :, 128])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Architecture\n",
    "\n",
    "I have somewhat better performance from a ViT. Might be due to better handling the gaps between slices. \n",
    "\n",
    "Also note the LogisticCumulativeLink as the final head layer. This allows learning a continuous severity feature from ordinal labels and vice versa for inference.\n",
    "\n",
    "<!-- ![](https://www.ethanrosenthal.com/2018/12/06/spacecutter-ordinal-regression/index_11_0.png) -->"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import timm_3d\n",
    "from spacecutter import *\n",
    "from spacecutter.losses import *\n",
    "from spacecutter.models import *\n",
    "from spacecutter.callbacks import *\n",
    "\n",
    "\n",
    "class CNN_Model_3D_Multihead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone=\"efficientnet_lite0\",\n",
    "                 in_chans=1,\n",
    "                 out_classes=5,\n",
    "                 cutpoint_margin=0.15,\n",
    "                 pretrained=False):\n",
    "        super(CNN_Model_3D_Multihead, self).__init__()\n",
    "        self.out_classes = out_classes\n",
    "\n",
    "        self.encoder = timm_3d.create_model(\n",
    "            backbone,\n",
    "            features_only=False,\n",
    "            drop_rate=0,\n",
    "            drop_path_rate=0,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_chans,\n",
    "            global_pool=\"max\"\n",
    "        )\n",
    "        if \"efficientnet\" in backbone:\n",
    "            head_in_dim = self.encoder.classifier.in_features\n",
    "            self.encoder.classifier = nn.Sequential(\n",
    "                nn.LayerNorm(head_in_dim),\n",
    "                nn.Dropout(0),\n",
    "            )\n",
    "\n",
    "        elif \"vit\" in backbone:\n",
    "            self.encoder.head.drop = nn.Dropout(0)\n",
    "            head_in_dim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(head_in_dim, 1),\n",
    "                LogisticCumulativeLink(3)\n",
    "            ) for i in range(out_classes)]\n",
    "        )\n",
    "\n",
    "        self.ascension_callback = AscensionCallback(margin=cutpoint_margin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        return torch.swapaxes(torch.stack([head(feat) for head in self.heads]), 0, 1)\n",
    "\n",
    "    def _ascension_callback(self):\n",
    "        for head in self.heads:\n",
    "            self.ascension_callback.clip(head[-1])"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN_Model_3D_Multihead(backbone=\"maxvit_rmlp_tiny_rw_256\", in_chans=3, out_classes=25).to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/rsna-2024/pytorch/vit_voxel_v2/6/maxvit_rmlp_tiny_rw_256_256_v2_fold_3_32.pt\"))"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"spinal_canal_stenosis\"],\n",
    "    \"Axial T2\": [\"left_subarticular_stenosis\", \"right_subarticular_stenosis\"],\n",
    "    \"Sagittal T1\": [\"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"],\n",
    "}\n",
    "\n",
    "ALL_CONDITIONS = sorted([\"spinal_canal_stenosis\", \"left_subarticular_stenosis\", \"right_subarticular_stenosis\", \"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"])\n",
    "LEVELS = [\"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\":[], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "\n",
    "ALL_CONDITIONS"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Pre-populate results df\n",
    "import glob\n",
    "import os\n",
    "\n",
    "study_ids = glob.glob(DATA_DIR + \"test_images/*\")\n",
    "study_ids = [os.path.basename(e) for e in study_ids]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\":[], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "for study_id in study_ids:\n",
    "    for condition in ALL_CONDITIONS:\n",
    "        for level in LEVELS:\n",
    "            row_id = f\"{study_id}_{condition}_{level}\"\n",
    "            results_df = results_df._append({\"row_id\": row_id, \"normal_mild\": 1/3, \"moderate\": 1/3, \"severe\": 1/3}, ignore_index=True)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.dataframe"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    with autocast(dtype=torch.float16):\n",
    "        model.eval()\n",
    "\n",
    "        for images, study_id in dataloader:\n",
    "            output = model(images.to(device))\n",
    "            for i, batch_out in enumerate(output):\n",
    "                batch_out = output.cpu().numpy()[i]\n",
    "                for index, level in enumerate(batch_out):\n",
    "                    row_id = f\"{study_id[i]}_{ALL_CONDITIONS[index // 5]}_{LEVELS[index % 5]}\"\n",
    "                    results_df.loc[results_df.row_id == row_id,'normal_mild'] = level[0]\n",
    "                    results_df.loc[results_df.row_id == row_id,'moderate'] = level[1]\n",
    "                    results_df.loc[results_df.row_id == row_id,'severe'] = level[2]\n",
    "                \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results_df"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results_df.to_csv('submission_9.csv', index=False)"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble submissions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# - option 17-> LB=0.48 work (7,9) + weights (0.257+0.743) \n",
    "# - option 18-> LB=0.48 work ( 7,9 ) + weights ( 0.33+0.67 )\n",
    "# - option 19-> LB=0.48 work ( 7,9 ) + weights ( 0.450+0.550 ) - previus.1 best option\n",
    "# - option 20-> LB=0.48 work ( 7,9 ) + weights ( 0.50+0.50 )\n",
    "# - option 23-> LB=0.48 work ( 7,9 ) + weights ( 0.473+0.527 )\n",
    "# - option 24-> LB=0.48 work ( 7,9 ) + weights ( 0.427+0.573 ) - previus.2 best option\n",
    "# - option 25-> LB=0.48 work ( 7,9 ) + weights ( 0.402+0.598 ) - previus.3 best option\n",
    "# - option 26-> LB=0.49 work ( 7,9 ) + weights ( 0.377+0.623 )\n",
    "# - **option 27**-> LB=**0.48** work ( 7,9 ) + weights ( 0.407+0.593 ) - **best option**\n",
    "# - option 28-> LB=0.48 work ( 7,9 ) + weights ( 0.395+0.605 )\n",
    "# - option 29-> LB=0.48 work ( 7,9 ) + weights ( 0.402+0.598 )\n",
    "# - option 30-> LB=0.48 work ( 7,9 ) + weights ( 0.405+0.595 )\n",
    "# - option 31-> LB=0.48 work ( 7,9 ) + weights ( 0.415+0.585 )\n",
    "# - option 32-> LB=0.48 work ( 7,9 ) + weights ( 0.410+0.590 )\n",
    "\n",
    "# some rezult:\n",
    "# * option.18 < option.20 < option.19 < option.24 == (version.48 < version.51 < version.49 < version.55-56)\n",
    "# * option.24 < option.25 == (version.55-56 < version.58)\n",
    "# * option.25 < option.28 < **option.27** == (version.58 < version.63 < **version.62**)\n",
    "# * option.29 < option.30 < **option.27** == (version.58 < version.63 < **version.62**)\n",
    "# * option.31 < option.32 < **option.27** == (version.58 < version.63 < **version.62**)\n",
    "\n",
    "# best option:\n",
    "# - option.32 < **option.27**\n",
    "\n",
    "# current option: \n",
    "# - option 33-> LB=0.4? work ( 8,9 ) + weights ( 0.407+0.593 )\n",
    "# - option 34-> LB=0.4? work ( 8,9 ) + weights ( 0.410+0.590 )\n",
    "\n",
    "# next option:\n",
    "# - option 16-> LB=0.4? work ( 7,8,9 ) + weights ( 0.25+0.20+0.55 )"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if LAUNCH_VARIANT == 'option 27':\n",
    "    sm7 = pd.read_csv('submission_7.csv')\n",
    "    sm9 = pd.read_csv('submission_9.csv')\n",
    "    display(sm7,sm9)\n",
    "    sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "    sms['normal_mild'] = sms['normal_mild_x'] *0.407 + 0.593* sms['normal_mild_y']\n",
    "    sms['moderate']    = sms['moderate_x']    *0.407 + 0.593* sms['moderate_y']\n",
    "    sms['severe']      = sms['severe_x']      *0.407 + 0.593* sms['severe_y']\n",
    "\n",
    "elif LAUNCH_VARIANT == 'option 31':\n",
    "    sm7 = pd.read_csv('submission_7.csv')\n",
    "    sm9 = pd.read_csv('submission_9.csv')\n",
    "    display(sm7,sm9)\n",
    "    sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "    sms['normal_mild'] = sms['normal_mild_x'] *0.415 + 0.585* sms['normal_mild_y']\n",
    "    sms['moderate']    = sms['moderate_x']    *0.415 + 0.585* sms['moderate_y']\n",
    "    sms['severe']      = sms['severe_x']      *0.415 + 0.585* sms['severe_y']\n",
    "\n",
    "elif LAUNCH_VARIANT == 'option 32':\n",
    "    sm7 = pd.read_csv('submission_7.csv')\n",
    "    sm9 = pd.read_csv('submission_9.csv')\n",
    "    display(sm7,sm9)\n",
    "    sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "    sms['normal_mild'] = sms['normal_mild_x'] *0.410 + 0.590* sms['normal_mild_y']\n",
    "    sms['moderate']    = sms['moderate_x']    *0.410 + 0.590* sms['moderate_y']\n",
    "    sms['severe']      = sms['severe_x']      *0.410 + 0.590* sms['severe_y']\n",
    "    \n",
    "elif LAUNCH_VARIANT == 'option 33':\n",
    "    sm8 = pd.read_csv('submission_8.csv')\n",
    "    sm9 = pd.read_csv('submission_9.csv')\n",
    "    display(sm8,sm9)\n",
    "    sms = pd.merge(sm8,sm9, on=['row_id'])\n",
    "    sms['normal_mild'] = sms['normal_mild_x'] *0.407 + 0.593* sms['normal_mild_y']\n",
    "    sms['moderate']    = sms['moderate_x']    *0.407 + 0.593* sms['moderate_y']\n",
    "    sms['severe']      = sms['severe_x']      *0.407 + 0.593* sms['severe_y']\n",
    "\n",
    "elif LAUNCH_VARIANT == 'option 34':\n",
    "    sm8 = pd.read_csv('submission_8.csv')\n",
    "    sm9 = pd.read_csv('submission_9.csv')\n",
    "    display(sm8,sm9)\n",
    "    sms = pd.merge(sm8,sm9, on=['row_id'])\n",
    "    sms['normal_mild'] = sms['normal_mild_x'] *0.410 + 0.590* sms['normal_mild_y']\n",
    "    sms['moderate']    = sms['moderate_x']    *0.410 + 0.590* sms['moderate_y']\n",
    "    sms['severe']      = sms['severe_x']      *0.410 + 0.590* sms['severe_y']"
   ],
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sub = sms[['row_id','normal_mild','moderate','severe']]\n",
    "sub.to_csv('submission.csv', index=False, float_format='%.7f')\n",
    "display(sub)"
   ],
   "metadata": {
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# if LAUNCH_VARIANT == 'option 29':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.402 + 0.598* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.402 + 0.598* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.402 + 0.598* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 30':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.405 + 0.595* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.405 + 0.595* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.405 + 0.595* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 28':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.395 + 0.605* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.395 + 0.605* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.395 + 0.605* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 27':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.407 + 0.593* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.407 + 0.593* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.407 + 0.593* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 26':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.377 + 0.523* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.377 + 0.523* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.377 + 0.523* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 25':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.402 + 0.598* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.402 + 0.598* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.402 + 0.598* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 24':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.427 + 0.573* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.427 + 0.573* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.427 + 0.573* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 23':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.473 + 0.527* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.473 + 0.527* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.473 + 0.527* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 22':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.58 + 0.42* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.58 + 0.42* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.58 + 0.42* sms['severe_y']\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 21':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.55 + 0.45* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.55 + 0.45* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.55 + 0.45* sms['severe_y']\n",
    "\n",
    "# if LAUNCH_VARIANT == 'option 20':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.50 + 0.50* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.50 + 0.50* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.50 + 0.50* sms['severe_y']\n",
    "\n",
    "# if LAUNCH_VARIANT == 'option 18':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.33 + 0.67* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.33 + 0.67* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.33 + 0.67* sms['severe_y']    \n",
    "\n",
    "# if LAUNCH_VARIANT == 'option 12':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.20 + 0.80* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.20 + 0.80* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.20 + 0.80* sms['severe_y']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 17':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm9)\n",
    "#     sms = pd.merge(sm7,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.257 + 0.743* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.257 + 0.743* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.257 + 0.743* sms['severe_y']    \n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 15':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm8 = pd.read_csv('submission_8.csv')\n",
    "#     display(sm7,sm8)\n",
    "#     sms = pd.merge(sm7,sm8, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.70 + 0.30* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.70 + 0.30* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.70 + 0.30* sms['severe_y']\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 16':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm8 = pd.read_csv('submission_8.csv')\n",
    "#     sm9 = pd.read_csv('submission_9.csv')\n",
    "#     display(sm7,sm8,sm9)\n",
    "#     sms = pd.merge(sm7,sm8, on=['row_id'])\n",
    "#     sms = pd.merge(sms,sm9, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.35 + 0.20* sms['normal_mild_y'] + 0.45* sms['normal_mild']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.35 + 0.20* sms['moderate_y']    + 0.45* sms['moderate']\n",
    "#     sms['severe']      = sms['severe_x']      *0.35 + 0.20* sms['severe_y']      + 0.45* sms['severe']\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 13':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm8 = pd.read_csv('submission_8.csv')\n",
    "#     display(sm7,sm8)\n",
    "#     sms = pd.merge(sm7,sm8, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.95 + 0.05* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.95 + 0.05* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.95 + 0.05* sms['severe_y']    \n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 14':\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     sm8 = pd.read_csv('submission_8.csv')\n",
    "#     display(sm7,sm8)\n",
    "#     sms = pd.merge(sm7,sm8, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.85 + 0.15* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.85 + 0.15* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.85 + 0.15* sms['severe_y']\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 10':\n",
    "#     sm6 = pd.read_csv('submission_6.csv')\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     display(sm6,sm7)\n",
    "#     sms = pd.merge(sm6,sm7, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.005 + 0.995* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.005 + 0.995* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.005 + 0.995* sms['severe_y']\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 11':\n",
    "#     sm5 = pd.read_csv('submission_5.csv')\n",
    "#     sm6 = pd.read_csv('submission_6.csv')\n",
    "#     sm7 = pd.read_csv('submission_7.csv')\n",
    "#     display(sm5,sm6,sm7)\n",
    "#     sms = pd.merge(sm5,sm6, on=['row_id'])\n",
    "#     sms = pd.merge(sm6,sm7, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.0005 + 0.0025* sms['normal_mild_y'] + 0.997* sms['normal_mild']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.0005 + 0.0025* sms['moderate_y']    + 0.997* sms['moderate']\n",
    "#     sms['severe']      = sms['severe_x']      *0.0005 + 0.0025* sms['severe_y']      + 0.997* sms['severe']\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 8':\n",
    "#     sm5 = pd.read_csv('submission_5.csv')\n",
    "#     sm6 = pd.read_csv('submission_6.csv')\n",
    "#     display(sm5,sm6)\n",
    "#     sms = pd.merge(sm5,sm6, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.90 + 0.10* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.90 + 0.10* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.90 + 0.10* sms['severe_y']\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 7':\n",
    "#     sm5 = pd.read_csv('submission_5.csv')\n",
    "#     sm6 = pd.read_csv('submission_6.csv')\n",
    "#     display(sm5,sm6)\n",
    "#     sms = pd.merge(sm5,sm6, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.50 + 0.50* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.50 + 0.50* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.50 + 0.50* sms['severe_y']\n",
    "    \n",
    "# if LAUNCH_VARIANT == 'option 1':\n",
    "#     sm1 = pd.read_csv('submission_1.csv')\n",
    "#     sm2 = pd.read_csv('submission_2.csv')\n",
    "#     display(sm1,sm2)\n",
    "#     sms = pd.merge(sm1,sm2, on=['row_id'])\n",
    "#     sms['normal_mild'] = (sms['normal_mild_x'] + sms['normal_mild_y']) / 2\n",
    "#     sms['moderate']    = (sms['moderate_x']    + sms['moderate_y'])    / 2\n",
    "#     sms['severe']      = (sms['severe_x']      + sms['severe_y'])      / 2\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 2':\n",
    "#     sm2 = pd.read_csv('submission_2.csv')\n",
    "#     sm3 = pd.read_csv('submission_3.csv')\n",
    "#     display(sm2,sm3)\n",
    "#     sms = pd.merge(sm2,sm3, on=['row_id'])\n",
    "#     sms['normal_mild'] = (sms['normal_mild_x'] + sms['normal_mild_y']) / 2\n",
    "#     sms['moderate']    = (sms['moderate_x']    + sms['moderate_y'])    / 2\n",
    "#     sms['severe']      = (sms['severe_x']      + sms['severe_y'])      / 2\n",
    "#     # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 3':\n",
    "#     sm3 = pd.read_csv('submission_3.csv')\n",
    "#     sm4 = pd.read_csv('submission_4.csv')\n",
    "#     display(sm3,sm4)\n",
    "#     sms = pd.merge(sm3,sm4, on=['row_id'])\n",
    "#     sms['normal_mild'] = (sms['normal_mild_x'] + sms['normal_mild_y']) / 2\n",
    "#     sms['moderate']    = (sms['moderate_x']    + sms['moderate_y'])    / 2\n",
    "#     sms['severe']      = (sms['severe_x']      + sms['severe_y'])      / 2\n",
    "#     # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "\n",
    "# elif LAUNCH_VARIANT == 'option 4':\n",
    "#     sm1 = pd.read_csv('submission_1.csv')\n",
    "#     sm2 = pd.read_csv('submission_2.csv')\n",
    "#     sm4 = pd.read_csv('submission_4.csv')\n",
    "#     display(sm1,sm2,sm4)\n",
    "#     sms = pd.merge(sm1,sm2, on=['row_id'])\n",
    "#     sms = pd.merge(sms,sm4, on=['row_id'])\n",
    "#     sms['normal_mild'] = (sms['normal_mild_x'] + sms['normal_mild_y'] + sms['normal_mild']) / 3\n",
    "#     sms['moderate']    = (sms['moderate_x']    + sms['moderate_y'])   + sms['moderate']     / 3\n",
    "#     sms['severe']      = (sms['severe_x']      + sms['severe_y'])     + sms['severe']       / 3\n",
    "#     # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 5':\n",
    "#     sm2 = pd.read_csv('submission_2.csv')\n",
    "#     sm3 = pd.read_csv('submission_3.csv')\n",
    "#     display(sm2,sm3)\n",
    "#     sms = pd.merge(sm2,sm3, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.45 + 0.55* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.45 + 0.55* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.45 + 0.55* sms['severe_y']\n",
    "#     # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "    \n",
    "# elif LAUNCH_VARIANT == 'option 6':\n",
    "#     sm2 = pd.read_csv('submission_2.csv')\n",
    "#     sm3 = pd.read_csv('submission_3.csv')\n",
    "#     display(sm2,sm3)\n",
    "#     sms = pd.merge(sm2,sm3, on=['row_id'])\n",
    "#     sms['normal_mild'] = sms['normal_mild_x'] *0.55 + 0.45* sms['normal_mild_y']\n",
    "#     sms['moderate']    = sms['moderate_x']    *0.55 + 0.45* sms['moderate_y']\n",
    "#     sms['severe']      = sms['severe_x']      *0.55 + 0.45* sms['severe_y']\n",
    "#     # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
