{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd98ba0",
   "metadata": {
    "papermill": {
     "duration": 0.007062,
     "end_time": "2024-09-11T18:16:45.078835",
     "exception": false,
     "start_time": "2024-09-11T18:16:45.071773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dependencies\n",
    "### timm_3d\n",
    "Timm models adapted for 3D data\n",
    "### torchio\n",
    "Medical imaging focused library. Used for 3D augmentations here\n",
    "### spacecutter\n",
    "Ordinal regression layer and related loss and callback functions i.e. `LogisticCumulativeLink`\n",
    "### open3d\n",
    "Used for point cloud initialization and transformation. At first I used this for voxelization too, but dropped it in favor of a simpler sampling approach due to slow runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf94a62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:16:45.093641Z",
     "iopub.status.busy": "2024-09-11T18:16:45.092841Z",
     "iopub.status.idle": "2024-09-11T18:19:08.406271Z",
     "shell.execute_reply": "2024-09-11T18:19:08.404830Z"
    },
    "papermill": {
     "duration": 143.322882,
     "end_time": "2024-09-11T18:19:08.408417",
     "exception": false,
     "start_time": "2024-09-11T18:16:45.085535",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-09-30T17:32:14.017201Z",
     "start_time": "2024-09-30T17:32:11.197676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Requirement '/kaggle/input/timm_3d_deps/other/initial/9/pydicom/pydicom/pydicom-2.4.4-py3-none-any.whl' looks like a filename, but the file does not exist\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/kaggle/input/timm_3d_deps/other/initial/9/pydicom/pydicom/pydicom-2.4.4-py3-none-any.whl'\r\n",
      "\u001B[0m\u001B[31m\r\n",
      "\u001B[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet /kaggle/input/timm_3d_deps/other/initial/9/pydicom/pydicom/pydicom-2.4.4-py3-none-any.whl\n",
    "%pip install timm_3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/timm_3d/\n",
    "%pip install torchio --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/torchio/\n",
    "%pip install itk --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/itk/itk\n",
    "%pip install skorch --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/skorch/skorch\n",
    "%pip install spacecutter --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/spacecutter/\n",
    "%pip install open3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/9/open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004ad4e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:08.424609Z",
     "iopub.status.busy": "2024-09-11T18:19:08.423932Z",
     "iopub.status.idle": "2024-09-11T18:19:08.428403Z",
     "shell.execute_reply": "2024-09-11T18:19:08.427578Z"
    },
    "papermill": {
     "duration": 0.014566,
     "end_time": "2024-09-11T18:19:08.430238",
     "exception": false,
     "start_time": "2024-09-11T18:19:08.415672",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-09-30T17:32:14.017725Z",
     "start_time": "2024-09-30T17:32:14.015852Z"
    }
   },
   "outputs": [],
   "source": [
    "#DATA_DIR = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/\"\n",
    "DATA_DIR = \"data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25b33de",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:08.445836Z",
     "iopub.status.busy": "2024-09-11T18:19:08.445564Z",
     "iopub.status.idle": "2024-09-11T18:19:09.242321Z",
     "shell.execute_reply": "2024-09-11T18:19:09.241158Z"
    },
    "papermill": {
     "duration": 0.807614,
     "end_time": "2024-09-11T18:19:09.244925",
     "exception": false,
     "start_time": "2024-09-11T18:19:08.437311",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-09-30T17:32:14.030368Z",
     "start_time": "2024-09-30T17:32:14.018305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   study_id   series_id series_description\n0  44036939  2828203845        Sagittal T1\n1  44036939  3481971518           Axial T2\n2  44036939  3844393089   Sagittal T2/STIR",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>series_id</th>\n      <th>series_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44036939</td>\n      <td>2828203845</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44036939</td>\n      <td>3481971518</td>\n      <td>Axial T2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44036939</td>\n      <td>3844393089</td>\n      <td>Sagittal T2/STIR</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def retrieve_test_data(DATA_DIR):\n",
    "    test_df = pd.read_csv(DATA_DIR + 'test_series_descriptions.csv')\n",
    "\n",
    "    return test_df\n",
    "\n",
    "retrieve_test_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f71d0cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:09.268381Z",
     "iopub.status.busy": "2024-09-11T18:19:09.267946Z",
     "iopub.status.idle": "2024-09-11T18:19:09.274875Z",
     "shell.execute_reply": "2024-09-11T18:19:09.273955Z"
    },
    "papermill": {
     "duration": 0.022164,
     "end_time": "2024-09-11T18:19:09.277804",
     "exception": false,
     "start_time": "2024-09-11T18:19:09.255640",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-09-30T17:32:14.030804Z",
     "start_time": "2024-09-30T17:32:14.029107Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def retrieve_image_paths(base_path, study_id, series_id):\n",
    "    series_dir = os.path.join(base_path, str(study_id), str(series_id))\n",
    "    images = os.listdir(series_dir)\n",
    "    image_paths = [os.path.join(series_dir, img) for img in images]\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a85eb6",
   "metadata": {
    "papermill": {
     "duration": 0.00901,
     "end_time": "2024-09-11T18:19:09.297471",
     "exception": false,
     "start_time": "2024-09-11T18:19:09.288461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "Quite a few things are happening here. Refer here for more details on where the affine transforms come from: https://nipy.org/nibabel/dicom/dicom_orientation.html\n",
    "\n",
    "The rough idea is -- converting the slices into point cloud format, transforming them into the same patient coordinate space, then converting into a voxel grid.\n",
    "\n",
    "1. Resizing each slice -- doing this first reduces the runtime from having to transform each point just to resize/downsample later anyway.\n",
    "2. Duplicating the slices and applying the affine transforms -- I found duplicating each slice by slice thickness makes it easier for the model to learn. The spatial information between slices might get somewhat warped, but the relative ordering is still the same but with much less empty space.\n",
    "3. Sampling into a voxel grid -- I am simply scaling the coordinates into the desired grid size, then sampling each channel by max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7c78b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:09.318552Z",
     "iopub.status.busy": "2024-09-11T18:19:09.318178Z",
     "iopub.status.idle": "2024-09-11T18:19:12.296355Z",
     "shell.execute_reply": "2024-09-11T18:19:12.295519Z"
    },
    "papermill": {
     "duration": 2.990971,
     "end_time": "2024-09-11T18:19:12.298780",
     "exception": false,
     "start_time": "2024-09-11T18:19:09.307809",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-09-30T17:32:14.036250Z"
    }
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "from pydicom import dcmread\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "def read_study_as_pcd(dir_path, series_types_dict=None, downsampling_factor=1, img_size=(256, 256)):\n",
    "    pcd_overall = o3d.geometry.PointCloud()\n",
    "\n",
    "    for path in glob.glob(os.path.join(dir_path, \"**/*.dcm\"), recursive=True):\n",
    "        dicom_slice = dcmread(path)\n",
    "\n",
    "        series_id = os.path.basename(os.path.dirname(path))\n",
    "        study_id = os.path.basename(os.path.dirname(os.path.dirname(path)))\n",
    "        if series_types_dict is None or int(series_id) not in series_types_dict:\n",
    "            series_desc = dicom_slice.SeriesDescription\n",
    "        else:\n",
    "            series_desc = series_types_dict[int(series_id)]\n",
    "            series_desc = series_desc.split(\" \")[-1]\n",
    "\n",
    "        x_orig, y_orig = dicom_slice.pixel_array.shape\n",
    "        img = np.expand_dims(cv2.resize(dicom_slice.pixel_array, img_size, interpolation=cv2.INTER_AREA), -1)\n",
    "        x, y, z = np.where(img)\n",
    "\n",
    "        downsampling_factor_iter = max(downsampling_factor, int(math.ceil(len(x) / 6e6)))\n",
    "\n",
    "        index_voxel = np.vstack((x, y, z))[:, ::downsampling_factor_iter]\n",
    "        grid_index_array = index_voxel.T\n",
    "        pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(grid_index_array.astype(np.float64)))\n",
    "\n",
    "        vals = np.expand_dims(img[x, y, z][::downsampling_factor_iter], -1)\n",
    "        if series_desc == \"T1\":\n",
    "            vals = np.pad(vals, ((0, 0), (0, 2)))\n",
    "        elif series_desc == \"T2\":\n",
    "            vals = np.pad(vals, ((0, 0), (1, 1)))\n",
    "        elif series_desc == \"T2/STIR\":\n",
    "            vals = np.pad(vals, ((0, 0), (2, 0)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown series desc: {series_desc}\")\n",
    "\n",
    "        pcd.colors = o3d.utility.Vector3dVector(vals.astype(np.float64))\n",
    "\n",
    "        dX, dY = dicom_slice.PixelSpacing\n",
    "        dZ = dicom_slice.SliceThickness\n",
    "\n",
    "        X = np.array(list(dicom_slice.ImageOrientationPatient[:3]) + [0]) * dX\n",
    "        Y = np.array(list(dicom_slice.ImageOrientationPatient[3:]) + [0]) * dY\n",
    "\n",
    "        for z in range(int(dZ)):\n",
    "            pos = list(dicom_slice.ImagePositionPatient)\n",
    "            if series_desc == \"T2\":\n",
    "                pos[-1] += z\n",
    "            else:\n",
    "                pos[0] += z\n",
    "            S = np.array(pos + [1])\n",
    "\n",
    "            transform_matrix = np.array([X, Y, np.zeros(len(X)), S]).T\n",
    "            transform_matrix = transform_matrix @ np.matrix(\n",
    "                [[0, y_orig / img_size[1], 0, 0],\n",
    "                 [x_orig / img_size[0], 0, 0, 0],\n",
    "                 [0, 0, 1, 0],\n",
    "                 [0, 0, 0, 1]]\n",
    "            )\n",
    "\n",
    "            pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n",
    "\n",
    "    return pcd_overall\n",
    "\n",
    "\n",
    "\n",
    "def read_study_as_voxel_grid(dir_path, series_type_dict=None, downsampling_factor=1, img_size=(256, 256)):\n",
    "    pcd_overall = read_study_as_pcd(dir_path,\n",
    "                                    series_types_dict=series_type_dict,\n",
    "                                    downsampling_factor=downsampling_factor,\n",
    "                                    img_size=img_size)\n",
    "    box = pcd_overall.get_axis_aligned_bounding_box()\n",
    "\n",
    "    max_b = np.array(box.get_max_bound())\n",
    "    min_b = np.array(box.get_min_bound())\n",
    "\n",
    "    pts = (np.array(pcd_overall.points) - (min_b)) * (\n",
    "                (img_size[0] - 1, img_size[0] - 1, img_size[0] - 1) / (max_b - min_b))\n",
    "    coords = np.round(pts).astype(np.int32)\n",
    "    vals = np.array(pcd_overall.colors, dtype=np.float16)\n",
    "\n",
    "    grid = np.zeros((3, img_size[0], img_size[0], img_size[0]), dtype=np.float16)\n",
    "    indices = coords[:, 0], coords[:, 1], coords[:, 2]\n",
    "\n",
    "    np.maximum.at(grid[0], indices, vals[:, 0])\n",
    "    np.maximum.at(grid[1], indices, vals[:, 1])\n",
    "    np.maximum.at(grid[2], indices, vals[:, 2])\n",
    "\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f8433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:12.315232Z",
     "iopub.status.busy": "2024-09-11T18:19:12.314756Z",
     "iopub.status.idle": "2024-09-11T18:19:16.711465Z",
     "shell.execute_reply": "2024-09-11T18:19:16.710672Z"
    },
    "papermill": {
     "duration": 4.407289,
     "end_time": "2024-09-11T18:19:16.713763",
     "exception": false,
     "start_time": "2024-09-11T18:19:12.306474",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchio as tio\n",
    "import torch.nn as nn\n",
    "import pydicom\n",
    "\n",
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"Spinal Canal Stenosis\"],\n",
    "    \"Axial T2\": [\"Left Subarticular Stenosis\", \"Right Subarticular Stenosis\"],\n",
    "    \"Sagittal T1\": [\"Left Neural Foraminal Narrowing\", \"Right Neural Foraminal Narrowing\"],\n",
    "}\n",
    "\n",
    "\n",
    "class PatientLevelTestset(Dataset):\n",
    "    def __init__(self,\n",
    "                 base_path: str,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 transform_3d=None):\n",
    "        self.base_path = base_path\n",
    "\n",
    "        self.dataframe = (dataframe[['study_id', \"series_id\", \"series_description\"]]\n",
    "                          .drop_duplicates())\n",
    "\n",
    "        self.subjects = self.dataframe[['study_id']].drop_duplicates().reset_index(drop=True)\n",
    "        self.series_descs = {e[0]: e[1] for e in self.dataframe[[\"series_id\", \"series_description\"]].drop_duplicates().values}\n",
    "\n",
    "        self.transform_3d = transform_3d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        curr = self.subjects.iloc[index]\n",
    "        study_path = os.path.join(self.base_path, str(curr[\"study_id\"]))\n",
    "\n",
    "        study_images = read_study_as_voxel_grid(study_path, self.series_descs)\n",
    "\n",
    "        if self.transform_3d is not None:\n",
    "            study_images = self.transform_3d(torch.FloatTensor(study_images))  # .data\n",
    "            return study_images.to(torch.half), str(curr[\"study_id\"])\n",
    "\n",
    "        return torch.HalfTensor(study_images), str(curr[\"study_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81903842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:16.730355Z",
     "iopub.status.busy": "2024-09-11T18:19:16.729858Z",
     "iopub.status.idle": "2024-09-11T18:19:16.734246Z",
     "shell.execute_reply": "2024-09-11T18:19:16.733409Z"
    },
    "papermill": {
     "duration": 0.01454,
     "end_time": "2024-09-11T18:19:16.736101",
     "exception": false,
     "start_time": "2024-09-11T18:19:16.721561",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "transform_3d = tio.Compose([\n",
    "    tio.RescaleIntensity([0, 1]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac01f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:16.751648Z",
     "iopub.status.busy": "2024-09-11T18:19:16.751358Z",
     "iopub.status.idle": "2024-09-11T18:19:16.756341Z",
     "shell.execute_reply": "2024-09-11T18:19:16.755581Z"
    },
    "papermill": {
     "duration": 0.014915,
     "end_time": "2024-09-11T18:19:16.758221",
     "exception": false,
     "start_time": "2024-09-11T18:19:16.743306",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def create_subject_level_testset_and_loader(df: pd.DataFrame,\n",
    "                                             transform_3d,\n",
    "                                             base_path: str,\n",
    "                                             batch_size=1,\n",
    "                                             num_workers=0):\n",
    "    testset = PatientLevelTestset(base_path, df, transform_3d=transform_3d)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return testset, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5207f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:16.773593Z",
     "iopub.status.busy": "2024-09-11T18:19:16.773289Z",
     "iopub.status.idle": "2024-09-11T18:19:16.790253Z",
     "shell.execute_reply": "2024-09-11T18:19:16.789563Z"
    },
    "papermill": {
     "duration": 0.026704,
     "end_time": "2024-09-11T18:19:16.792041",
     "exception": false,
     "start_time": "2024-09-11T18:19:16.765337",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data = retrieve_test_data(DATA_DIR)\n",
    "dataset, dataloader = create_subject_level_testset_and_loader(data, transform_3d, os.path.join(DATA_DIR, \"test_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d8ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:16.807404Z",
     "iopub.status.busy": "2024-09-11T18:19:16.807097Z",
     "iopub.status.idle": "2024-09-11T18:19:35.807877Z",
     "shell.execute_reply": "2024-09-11T18:19:35.806969Z"
    },
    "papermill": {
     "duration": 19.011764,
     "end_time": "2024-09-11T18:19:35.810941",
     "exception": false,
     "start_time": "2024-09-11T18:19:16.799177",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "import torch\n",
    "\n",
    "grid = dataset[0][0]\n",
    "\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "\n",
    "axs[0, 0].imshow(grid[0, 128])\n",
    "axs[1, 0].imshow(grid[1, 128])\n",
    "axs[2, 0].imshow(grid[2, 128])\n",
    "\n",
    "axs[0, 1].imshow(grid[0, :, 128])\n",
    "axs[1, 1].imshow(grid[1, :, 128])\n",
    "axs[2, 1].imshow(grid[2, :, 128])\n",
    "\n",
    "axs[0, 2].imshow(grid[0, :, :, 128])\n",
    "axs[1, 2].imshow(grid[1, :, :, 128])\n",
    "axs[2, 2].imshow(grid[2, :, :, 128])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7aae55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:35.830693Z",
     "iopub.status.busy": "2024-09-11T18:19:35.830385Z",
     "iopub.status.idle": "2024-09-11T18:19:35.837169Z",
     "shell.execute_reply": "2024-09-11T18:19:35.836297Z"
    },
    "papermill": {
     "duration": 0.018582,
     "end_time": "2024-09-11T18:19:35.839032",
     "exception": false,
     "start_time": "2024-09-11T18:19:35.820450",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb7850",
   "metadata": {
    "papermill": {
     "duration": 0.008958,
     "end_time": "2024-09-11T18:19:35.857013",
     "exception": false,
     "start_time": "2024-09-11T18:19:35.848055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Architecture\n",
    "\n",
    "I have somewhat better performance from a ViT. Might be due to better handling the gaps between slices. \n",
    "\n",
    "Also note the LogisticCumulativeLink as the final head layer. This allows learning a continuous severity feature from ordinal labels and vice versa for inference.\n",
    "\n",
    "![](https://www.ethanrosenthal.com/2018/12/06/spacecutter-ordinal-regression/index_11_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c513674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:35.876229Z",
     "iopub.status.busy": "2024-09-11T18:19:35.875923Z",
     "iopub.status.idle": "2024-09-11T18:19:38.900399Z",
     "shell.execute_reply": "2024-09-11T18:19:38.899454Z"
    },
    "papermill": {
     "duration": 3.036861,
     "end_time": "2024-09-11T18:19:38.902895",
     "exception": false,
     "start_time": "2024-09-11T18:19:35.866034",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import timm_3d\n",
    "from spacecutter import *\n",
    "from spacecutter.losses import *\n",
    "from spacecutter.models import *\n",
    "from spacecutter.callbacks import *\n",
    "\n",
    "\n",
    "class CNN_Model_3D_Multihead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone=\"efficientnet_lite0\",\n",
    "                 in_chans=1,\n",
    "                 out_classes=5,\n",
    "                 cutpoint_margin=0.15,\n",
    "                 pretrained=False):\n",
    "        super(CNN_Model_3D_Multihead, self).__init__()\n",
    "        self.out_classes = out_classes\n",
    "\n",
    "        self.encoder = timm_3d.create_model(\n",
    "            backbone,\n",
    "            features_only=False,\n",
    "            drop_rate=0,\n",
    "            drop_path_rate=0,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_chans,\n",
    "            global_pool=\"max\"\n",
    "        )\n",
    "        if \"efficientnet\" in backbone:\n",
    "            head_in_dim = self.encoder.classifier.in_features\n",
    "            self.encoder.classifier = nn.Sequential(\n",
    "                nn.LayerNorm(head_in_dim),\n",
    "                nn.Dropout(0),\n",
    "            )\n",
    "\n",
    "        elif \"vit\" in backbone:\n",
    "            self.encoder.head.drop = nn.Dropout(0)\n",
    "            head_in_dim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(head_in_dim, 1),\n",
    "                LogisticCumulativeLink(3)\n",
    "            ) for i in range(out_classes)]\n",
    "        )\n",
    "\n",
    "        self.ascension_callback = AscensionCallback(margin=cutpoint_margin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        return torch.swapaxes(torch.stack([head(feat) for head in self.heads]), 0, 1)\n",
    "\n",
    "    def _ascension_callback(self):\n",
    "        for head in self.heads:\n",
    "            self.ascension_callback.clip(head[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd378922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:38.923634Z",
     "iopub.status.busy": "2024-09-11T18:19:38.923285Z",
     "iopub.status.idle": "2024-09-11T18:19:40.930565Z",
     "shell.execute_reply": "2024-09-11T18:19:40.929553Z"
    },
    "papermill": {
     "duration": 2.020674,
     "end_time": "2024-09-11T18:19:40.933416",
     "exception": false,
     "start_time": "2024-09-11T18:19:38.912742",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model = CNN_Model_3D_Multihead(backbone=\"maxvit_rmlp_tiny_rw_256\", in_chans=3, out_classes=25).to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/rsna-2024/pytorch/vit_voxel_v2/6/maxvit_rmlp_tiny_rw_256_256_v2_fold_3_32.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877fb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:40.954718Z",
     "iopub.status.busy": "2024-09-11T18:19:40.954420Z",
     "iopub.status.idle": "2024-09-11T18:19:40.962991Z",
     "shell.execute_reply": "2024-09-11T18:19:40.962136Z"
    },
    "papermill": {
     "duration": 0.021114,
     "end_time": "2024-09-11T18:19:40.964880",
     "exception": false,
     "start_time": "2024-09-11T18:19:40.943766",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "CONDITIONS = {\n",
    "    \"Sagittal T2/STIR\": [\"spinal_canal_stenosis\"],\n",
    "    \"Axial T2\": [\"left_subarticular_stenosis\", \"right_subarticular_stenosis\"],\n",
    "    \"Sagittal T1\": [\"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"],\n",
    "}\n",
    "\n",
    "ALL_CONDITIONS = sorted([\"spinal_canal_stenosis\", \"left_subarticular_stenosis\", \"right_subarticular_stenosis\", \"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\"])\n",
    "LEVELS = [\"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\":[], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "\n",
    "ALL_CONDITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a3ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:40.985893Z",
     "iopub.status.busy": "2024-09-11T18:19:40.985196Z",
     "iopub.status.idle": "2024-09-11T18:19:41.016846Z",
     "shell.execute_reply": "2024-09-11T18:19:41.015988Z"
    },
    "papermill": {
     "duration": 0.043994,
     "end_time": "2024-09-11T18:19:41.018792",
     "exception": false,
     "start_time": "2024-09-11T18:19:40.974798",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Pre-populate results df\n",
    "import glob\n",
    "import os\n",
    "\n",
    "study_ids = glob.glob(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/*\")\n",
    "study_ids = [os.path.basename(e) for e in study_ids]\n",
    "\n",
    "results_df = pd.DataFrame({\"row_id\":[], \"normal_mild\": [], \"moderate\": [], \"severe\": []})\n",
    "for study_id in study_ids:\n",
    "    for condition in ALL_CONDITIONS:\n",
    "        for level in LEVELS:\n",
    "            row_id = f\"{study_id}_{condition}_{level}\"\n",
    "            results_df = results_df._append({\"row_id\": row_id, \"normal_mild\": 1/3, \"moderate\": 1/3, \"severe\": 1/3}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47292456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:41.039133Z",
     "iopub.status.busy": "2024-09-11T18:19:41.038825Z",
     "iopub.status.idle": "2024-09-11T18:19:41.047284Z",
     "shell.execute_reply": "2024-09-11T18:19:41.046406Z"
    },
    "papermill": {
     "duration": 0.020601,
     "end_time": "2024-09-11T18:19:41.049146",
     "exception": false,
     "start_time": "2024-09-11T18:19:41.028545",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "dataset.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0390abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:41.070816Z",
     "iopub.status.busy": "2024-09-11T18:19:41.070171Z",
     "iopub.status.idle": "2024-09-11T18:19:59.524873Z",
     "shell.execute_reply": "2024-09-11T18:19:59.523876Z"
    },
    "papermill": {
     "duration": 18.467694,
     "end_time": "2024-09-11T18:19:59.527125",
     "exception": false,
     "start_time": "2024-09-11T18:19:41.059431",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    with autocast(dtype=torch.float16):\n",
    "        model.eval()\n",
    "\n",
    "        for images, study_id in dataloader:\n",
    "            output = model(images.to(device))\n",
    "            for i, batch_out in enumerate(output):\n",
    "                batch_out = output.cpu().numpy()[i]\n",
    "                for index, level in enumerate(batch_out):\n",
    "                    row_id = f\"{study_id[i]}_{ALL_CONDITIONS[index // 5]}_{LEVELS[index % 5]}\"\n",
    "                    results_df.loc[results_df.row_id == row_id,'normal_mild'] = level[0]\n",
    "                    results_df.loc[results_df.row_id == row_id,'moderate'] = level[1]\n",
    "                    results_df.loc[results_df.row_id == row_id,'severe'] = level[2]\n",
    "                \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738e6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:59.548279Z",
     "iopub.status.busy": "2024-09-11T18:19:59.547936Z",
     "iopub.status.idle": "2024-09-11T18:19:59.562036Z",
     "shell.execute_reply": "2024-09-11T18:19:59.561178Z"
    },
    "papermill": {
     "duration": 0.026687,
     "end_time": "2024-09-11T18:19:59.563948",
     "exception": false,
     "start_time": "2024-09-11T18:19:59.537261",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9fe3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:19:59.585874Z",
     "iopub.status.busy": "2024-09-11T18:19:59.585608Z",
     "iopub.status.idle": "2024-09-11T18:19:59.592001Z",
     "shell.execute_reply": "2024-09-11T18:19:59.591302Z"
    },
    "papermill": {
     "duration": 0.019412,
     "end_time": "2024-09-11T18:19:59.593911",
     "exception": false,
     "start_time": "2024-09-11T18:19:59.574499",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "modelId": 89293,
     "modelInstanceId": 64905,
     "sourceId": 100132,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 84065,
     "modelInstanceId": 85952,
     "sourceId": 111113,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 199.774424,
   "end_time": "2024-09-11T18:20:02.157626",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-11T18:16:42.383202",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
